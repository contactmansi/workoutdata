{
  
    
        "post0": {
            "title": "Classify faces using Traditional Machine Learning Algorithms",
            "content": "Explore the power of traditional ML algorithms on image classification problem using a curated faces dataset. It is true that we can achieve reasonable performance on an image classification task by fitting a simple Machine Learning (ML) algorithm such as KNearestNeighbours (KNN) or Random Forest Classifiers. Principal Component Analysis (PCA) can be effectively used to reduce number of features. We will evaluate classification performance by training KNNs and Random Forests on features that are computed from the raw pixels reduced by PCA. . Setup Files . face: Database of face images | FisherFace.py: Helps compute PCA features | Files and Steps to setup can be found on Github | . Database . The image files have names ppppp_xx_yy.bmp, where ppppp denotes the identity of the person called person ID; xx denotes the head orientation (we can ignore that, since in this dataset all images have same head orientation); and yy denotes the lighting condition. All images have been cropped and aligned with a height, width of 160, 140 pixels respectively. . Attention: . python3.x is preferred | We do not require a GPU, CPU is enough. | . After setting up virtual environment import libraries and FisherFace.py . import FisherFace import numpy as np import matplotlib.pyplot as plt from sklearn.neighbors import KNeighborsClassifier from sklearn.ensemble import RandomForestClassifier from sklearn.metrics import accuracy_score . Read faces from the database path . database_path = &quot;./face/&quot; faces, ids = FisherFace.read_faces(database_path) ## Check the data shapes ## Note: `faces` HAS THE WHOLE DATABASE, NOT SPLIT INTO TRAIN &amp; TEST print(faces.shape, ids.shape) . (22400, 240) (240,) . Task 1: Let&#39;s answer the following questions to understand the faces data . Question 1 How many instances, and how many classes in this dataset? . unique_ids, counts = np.unique(ids, return_counts=True) print(f&quot;Total classes in faces dataset: {len(unique_ids)}&quot;) print(f&quot;Total instances: {len(ids)}&quot;) print(f&quot;Instances for each class label: n{unique_ids} n{counts}&quot;) . Total classes in faces dataset: 10 Total instances: 240 Instances for each class label: [0 1 2 3 4 5 6 7 8 9] [24 24 24 24 24 24 24 24 24 24] . Question 2 What is the shape of each image instance? . # imports import cv2 import os # list all images in a list from face folder images = os.listdir(database_path) # create a dictionary to store dimentions for each image dimensions = dict() # Loop to store dimensions of each image in dimension dictionary for image in images: image_path = os.path.join(database_path,image) image = cv2.imread(image_path) dimensions[image_path] = image.shape # Print unique values for dimensions from different images print(f&quot;Shape in (height, width, number of channels) of each image is: {set(dimensions.values())}&quot;) print(&quot;Observe that single value from dimensions dictionary means that all images have the same dimension as above.&quot;) . Shape in (height, width, number of channels) of each image is: {(160, 140, 3)} Observe that single value from dimensions dictionary means that all images have the same dimension as above. . Question 3 Does this dataset have balanced classes? . print(f&quot;Instances for each class label: n{unique_ids} n{counts}&quot;) print(&quot;Yes, this dataset has balanced classes because the number of images for each person/class label is 24&quot;) . Instances for each class label: [0 1 2 3 4 5 6 7 8 9] [24 24 24 24 24 24 24 24 24 24] Yes, this dataset has balanced classes because the number of images for each person/class label is 24 . Task 2: Visualize the Data . For each of the persons, visualize 2 face images with matplotlib subplot grid. | . # I have chosen to print 5th and 10th image out of 24 images for each of the 10 people in dataset img_arr = [] for image in images: # Choose 5th and 10th image for each person if &#39;_04.bmp&#39; in image or &#39;_09.bmp&#39; in image: img_arr.append(image) img_arr.sort() n_row, n_col = 2, 10 _, axs = plt.subplots(n_row, n_col, figsize=(15, 4)) axs = axs.flatten() for img, ax in zip(img_arr, axs): image_path = &#39;./face/&#39;+img image = cv2.imread(image_path) ax.axis(&quot;off&quot;) ax.imshow(image) label = img.split(&#39;_&#39;)[0][-1] ax.set_title(f&#39;ID={label}&#39;, color=&#39;black&#39;) plt.show() . Task 3: Randomly split your data into Train, Test set . There are 24 images for each person. . Randomly split these into two sets of equal size. That is, your train and test sets will have 12 images for each per person. | Read train and test faces using FisherFace.read_faces(path). | . from sklearn.model_selection import train_test_split import shutil import pandas as pd def copy_files(source, destination, files): # source: https://www.geeksforgeeks.org/python-shutil-copy-method/ try: for file in files: shutil.copy(os.path.join(source, file), destination) print(&quot;Images copied succesfully&quot;) # If source and destination are same except shutil.SameFileError: print(&quot;Source and destination represents the same file.&quot;) # For other errors except: print(&quot;Error occurred while copying file.&quot;) def get_train_test_faces(database_path, train_ratio=0.8): &quot;&quot;&quot; Split data and return train, test and validation splits INPUT: train_ratio : Percentage of training data required in total, test_ratio = 1.00 - train_ratio RETURN: traintrain_faces, train_ids, test_faces, test_ids HINT: first list the images in the database, group into each classes, then randomly choose from each classes according to train_ratio, copy and store those face images in two folders: &#39;train&#39; and &#39;test&#39;, use `FisherFace.read_faces(path)` for reading face [This hint is just a suggestion, you can use your own technique] &quot;&quot;&quot; ## TODO: Your code here # first list the images in the database images = os.listdir(database_path) # randomly choose from each class using stratify on images_df and according to train_ratio and train, test = train_test_split(images, test_size=(1-train_ratio), stratify=ids, random_state=42) # create test and train destination folders to copy files train_path = &#39;./train/&#39; test_path = &#39;./test/&#39; if not os.path.exists(train_path): os.mkdir(train_path) if not os.path.exists(test_path): os.mkdir(test_path) # copy and store face images using user-defined utility function copy_files() copy_files(database_path, train_path, train) copy_files(database_path, test_path, test) # use `FisherFace.read_faces(path)` for reading face train_faces, train_ids = FisherFace.read_faces(train_path) test_faces, test_ids = FisherFace.read_faces(test_path) return train_faces, train_ids, test_faces, test_ids . train_faces, train_ids, test_faces, test_ids = get_train_test_faces(database_path=database_path, train_ratio=0.5) print(train_faces.shape, train_ids.shape) print(test_faces.shape, test_ids.shape) . Images copied succesfully Images copied succesfully (22400, 120) (120,) (22400, 120) (120,) . Compute PCA . def train_PCA(data, D): &quot;&quot;&quot; &#39;data&#39;: self explanatory &#39;D&#39;: Projection dimension, we retain only top &#39;D&#39; eigenfaces RETURN &#39;W&#39;: PCA projection matrix &#39;LL&#39;: eigenvalues &#39;m&#39;: global mean vector &quot;&quot;&quot; W, LL, m = FisherFace.myPCA(data) W = W[:,:D] return W, LL, m def get_face_features(data, W, m): r, c = data.shape mean_faces = data - np.tile(m, (c, 1)).T features = np.dot(W.T, mean_faces) return features . Task 4: Compute PCA feature from face images . Compute PCA feature from face images. . Use the code in the block above to: . Train PCA Projection Matrix from the train_faces using the function in the block above: train_PCA(data, D). | Get the train and test face-features using the function get_face_features(data, W, m). | # randomly observing 25 dimensions to pick optimum n_components for PCA dimensions D=25 PCA_proj_matrix, Eigenvalues, g_mean_vector = train_PCA(train_faces, D) train_features = get_face_features(train_faces, PCA_proj_matrix, g_mean_vector) # estimating the apt number of projection dimensions D pca_variance = pd.DataFrame ({&quot;D&quot;:range(1, D+1), &quot;variance&quot;:np.round(np.sum(train_features**2, axis=1),3)/10**7}) plt.plot(pca_variance.D, pca_variance.variance, linestyle=&#39;-&#39;, marker=&#39;o&#39;) plt.title(&quot;PCA Dimensions D vs Variance&quot;) plt.show() print(pca_variance) . D variance 0 1 428.521854 1 2 164.701332 2 3 57.638644 3 4 28.068231 4 5 21.346938 5 6 16.820264 6 7 13.485714 7 8 10.392261 8 9 8.792255 9 10 8.114008 10 11 6.069622 11 12 3.831245 12 13 3.061438 13 14 2.917512 14 15 2.729116 15 16 2.311011 16 17 1.938575 17 18 1.670512 18 19 1.516909 19 20 1.383781 20 21 1.295904 21 22 1.201229 22 23 1.021337 23 24 0.899807 24 25 0.855575 . D=12 seems to be apt dimension because the change is variance is limited on increasing dimension beyond 12 . # D=12 seems to be apt dimension because the change is variance is limited on increasing dimension beyond 12 D=12 PCA_proj_matrix, Eigenvalues, mean_vector = train_PCA(train_faces, D) # Compute the train features # TODO: Your code here train_features = get_face_features(train_faces, PCA_proj_matrix, g_mean_vector) # Compute the test features # TODO: Your code here test_features = get_face_features(test_faces, PCA_proj_matrix, g_mean_vector) display( train_features.shape, test_features.shape ) . (12, 120) . (12, 120) . Task 5: Train the sklearn KNN to classify the images (4 marks) . Use scikit learn to train kNN classifiers with this training set by varying the value for k (k = 3, 5, 7). | Evaluate the classifier with the test dataset by computing the accuracy for each classifier. | . def kNearestNeighbors(k, train_features, train_labels, test_features, test_labels): &quot;&quot;&quot; &#39;k&#39;: number of neighbors &#39;train_features&#39;: train face features &#39;train_labels&#39;: train data labels &#39;test_features&#39;: test face features &#39;test_labels&#39;: test data labels RETURN &#39;accuracy&#39;: floating point value, accuracy of the model on `test_features` &quot;&quot;&quot; knn = KNeighborsClassifier(n_neighbors = k, n_jobs=-1).fit(train_features.T, train_labels) y_pred = knn.predict(test_features.T) return accuracy_score(test_labels, y_pred) . k_list = [3, 5, 7] # fill up the list to test more neighbours acc_list_knn = [] for k in k_list: # TODO: Your code here acc = kNearestNeighbors(k, train_features, train_ids, test_features, test_ids) acc_list_knn.append(acc) print(f&#39;{k=}, {acc=: .2f}&#39;) . k=3, acc= 0.85 k=5, acc= 0.78 k=7, acc= 0.73 . Task 6: Visualize your results from KNN . Question 1: Plot k value vs accuracy . plt.plot(k_list, acc_list_knn, linestyle=&#39;-&#39;, marker=&#39;o&#39;, color=&#39;red&#39;,label=&quot;k vs accuracy&quot;) plt.title(&quot;KNN k-value vs accuracy&quot;) plt.xlabel(&quot;k-value&quot;) plt.ylabel(&quot;Accuracy&quot;) plt.show() . Question 2: Calculate the confusion matrix for k = 5. . from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix k = 5 knn = KNeighborsClassifier(n_neighbors=k, n_jobs=-1).fit(train_features.T, train_ids) cm = confusion_matrix(test_ids, knn.predict(test_features.T)) cm_disp = ConfusionMatrixDisplay(confusion_matrix=cm) cm_disp.plot() plt.show() . Question 3: Find the 5 nearest neighbors for one of the faces from the test set and visualize them. . You can use any of the kNN models, and choose any of the faces for this question. . neighbors = knn.kneighbors(test_features.T[0].reshape(1,-1))[1].reshape(-1) neighbors_features = train_faces[:, neighbors] neighbors_id = train_ids[neighbors] print(f&quot;Actual Test ID of first data point is {test_ids[0]}. nIDs of Neighbours selected by KNN from training data are: {neighbors_id}&quot;) n_row, n_col = 1, 5 fig, axs = plt.subplots(n_row, n_col, figsize=(15, 4)) axs = axs.flatten() fig.suptitle(f&quot;Visualizing {k} Nearest Neighbours Selected by KNN for First Data Point from Test Data&quot;) for i, ax in enumerate(axs): ax.axis(&quot;off&quot;) ax.imshow(neighbors_features[:,i].reshape(160,140), cmap=plt.cm.gray) ax.set_title(f&#39;ID={str(neighbors_id[i])}&#39;) plt.show() . Actual Test ID of first data point is 9. IDs of Neighbours selected by KNN from training data are: [9 9 9 3 3] . Task 7: Train the sklearn Random Forest to classify the images . Use scikit learn to train a Random Forest classifier for the same training set. | Change different values for the parameter n_estimators in the Random Forest. | . def RandomForest(n_estimators, train_features, train_labels, test_features, test_labels): &quot;&quot;&quot; &#39;n_estimators&#39;: number of estimators &#39;train_features&#39;: train face features &#39;train_labels&#39;: train data labels &#39;test_features&#39;: self explanatory &#39;test_labels&#39;: test data labels RETURN &#39;accuracy&#39;: floating point value, accuracy of the model on `test_features` &quot;&quot;&quot; # TODO: Your code here random_forest = RandomForestClassifier(n_estimators = n_estimators, n_jobs=-1).fit(train_features.T, train_labels) y_pred = random_forest.predict(test_features.T) return accuracy_score(test_labels, y_pred) . n_est_list = [20, 40, 60, 80, 100, 120] # fill up the list acc_list_rf = [] for n_est in n_est_list: # TODO: Your code here accuracy = RandomForest(n_est, train_features, train_ids, test_features, test_ids) acc_list_rf.append(accuracy) print(f&#39;{n_est=}, {accuracy=: .2f}&#39;) . n_est=20, accuracy= 1.00 n_est=40, accuracy= 1.00 n_est=60, accuracy= 1.00 n_est=80, accuracy= 1.00 n_est=100, accuracy= 1.00 n_est=120, accuracy= 1.00 . Task 8: Visualize your results from Random Forest . Question 1: Visualize the change in accuracy when n_estimators is changed as above. . plt.plot(n_est_list, acc_list_rf, linestyle=&#39;-&#39;, marker=&#39;o&#39;) plt.title(&quot;Random Forest n_estimators vs accuracy&quot;) plt.xlabel(&quot;n_estimators&quot;) plt.ylabel(&quot;Accuracy&quot;) plt.show() . Question 2: Calculate the confusion matrix for n_estimators = 100. . n_estimators = 100 random_forest = RandomForestClassifier(n_estimators=n_estimators, n_jobs=-1).fit(train_features.T, train_ids) cm = confusion_matrix(test_ids, random_forest.predict(test_features.T)) cm_disp = ConfusionMatrixDisplay(confusion_matrix=cm) cm_disp.plot() plt.show() . Question 3: Visualize 10 test face images randomly along with their predicted values. . import random random.seed(8968) # generating 10 random labels from [0,120) random_test_idx = random.sample(range(120), 10) # getting actual labels/IDs of these randomly selected 10 test face images from test_ids random_test_labels = test_ids[random_test_idx] # getting features of these randomly selected 10 test face images from test_faces random_test_features = test_faces[:, random_test_idx] # getting prediction labels/IDs for random images using random forest trained model on PCA reduced test_features predicted_labels = random_forest.predict(test_features.T[random_test_idx]) print(&quot;Randomly selected 10 test images Actual labels :&quot;, random_test_labels) print(&quot;Random Forest Trained Model Prediction labels : &quot;, predicted_labels) n_row, n_col = 2,5 fig, axs = plt.subplots(n_row, n_col, figsize=(15, 8)) fig.suptitle(f&quot;Visualizing 10 test face images randomly along with their predicted values by Random Forest&quot;) axs = axs.flatten() for i, ax in enumerate(axs): ax.axis(&quot;off&quot;) ax.imshow(random_test_features[:, i].reshape(160,140), cmap=plt.cm.gray) ax.set_title(f&#39;Actual ID={random_test_labels[i]} nPredicted ID={predicted_labels[i]}&#39;) plt.show() . Randomly selected 10 test images Actual labels : [2 5 4 4 8 3 5 8 4 3] Random Forest Trained Model Prediction labels : [2 5 4 4 8 3 5 8 4 3] . Congratulations! We have successfully trained our own image classifiers using traditional ML Algorithms .",
            "url": "https://contactmansi.github.io/workoutdata/image-analytics/knn/random%20forest/pca/classification/faces-dataset/2022/03/11/facial_recognition_using_basic_ml.html",
            "relUrl": "/image-analytics/knn/random%20forest/pca/classification/faces-dataset/2022/03/11/facial_recognition_using_basic_ml.html",
            "date": " • Mar 11, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "Must Follow Data Science Resources",
            "content": "Python Data Science Resources . Python Data Science Handbook by Jake VanderPlas . | This website contains the full text of the Python Data Science Handbook by Jake VanderPlas; the content is available on GitHub in the form of Jupyter notebooks. . Data Mining Techniques . | . NLP Resources . NLP 101: Word2Vec — Skip-gram and CBOW . | Very rightly stated by author Ria Kulshrestha. This post is “A crash course in word embedding.” .",
            "url": "https://contactmansi.github.io/workoutdata/markdown/2022/03/11/Must-Follow-DS-Resources.html",
            "relUrl": "/markdown/2022/03/11/Must-Follow-DS-Resources.html",
            "date": " • Mar 11, 2022"
        }
        
    
  
    
        ,"post2": {
            "title": "Backend Architecture & Development Resources",
            "content": "Backend Architecture &amp; Development Resources . Principles &amp; Best practices of REST API Design | REST Architecture Style Explained | REST vs RESTful API | Git/GitHub . GitHub Education Git Cheat Sheet | Linux . Linux Training Academy Linus Commands Cheat Sheet |",
            "url": "https://contactmansi.github.io/workoutdata/markdown/2022/03/05/Backend_Resources_Development-Resources.html",
            "relUrl": "/markdown/2022/03/05/Backend_Resources_Development-Resources.html",
            "date": " • Mar 5, 2022"
        }
        
    
  
    
        ,"post3": {
            "title": "Facial Recognition using Convolutional Neural Network (CNN)",
            "content": "import keras from keras.models import Sequential from keras.layers import Dense, Input, Conv2D, Flatten, MaxPooling2D from sklearn.model_selection import train_test_split from sklearn.datasets import fetch_olivetti_faces import numpy as np import scipy as sp import matplotlib.pyplot as plt import warnings . %matplotlib inline warnings.filterwarnings(&#39;ignore&#39;) # set the random seed to make the experiment reproducible random_seed = 1 np.random.seed(random_seed) . Working with Faces Image Data: CNNs . Convolutional Neural Network (CNN) is especially suited for feature extraction of image data. A CNN is a neural network typically composed of two components, one component for extracting useful features of the data, and another for performing a ML task (like classification based on the featurized data). We will also compare the performances and number of parameteres between Fully-Connected NNs (FCNNs) and CNNs. . In this article we also obtain and visualize how to obtain weight parameters for convolutional layer and outputs of convolution and MaxPooling Layer. Visualizing helps us enhance our interpretability of how the images are changing when passing through different layers and cnn model is training on image dataset. . image_shape = (64, 64) # load faces data faces_dataset = fetch_olivetti_faces(shuffle=True, random_state=random_seed) faces = faces_dataset.data n_samples, n_features = faces.shape # function to visualize images def plot_face(ax, img, image_shape): vmax = max(img.max(), -img.min()) ax.imshow(img.reshape(image_shape), cmap=plt.cm.gray, interpolation=&#39;nearest&#39;, vmin=-vmax, vmax=vmax) return ax . labels = faces_dataset.target # take images from only two individuals X_flat = faces[(labels == 0) | (labels == 1)] X = X_flat.reshape((20, 64, 64, 1)) Y = labels[(labels == 0) | (labels == 1)] . fig, ax = plt.subplots(1, 2, figsize=(10, 5)) ax[0] = plot_face(ax[0], X[Y == 0][0], image_shape) ax[1] = plot_face(ax[1], X[Y == 1][0], image_shape) plt.show() . I. Classification with a FNN . Task #1: Build a shallow FNN to classify the face images. . Only one hidden layer and its hidden layer size is 4 | Activation function is set to be relu | input_dim = X_flat.shape[1] H = input_dim hidden_size = 4 # create sequential multi-layer perceptron FCNN = Sequential() #input layer FCNN.add(Input(shape=(input_dim, ))) #hidden layer FCNN.add(Dense(hidden_size, activation=&#39;relu&#39;, name=&#39;hidden_layer&#39;)) #binary classification, one output FCNN.add(Dense(1, activation=&#39;sigmoid&#39;, name=&#39;Classification_output_layer&#39;)) # configure the model FCNN.compile(loss=&#39;binary_crossentropy&#39;,metrics=[&#39;acc&#39;]) . Metal device set to: Apple M1 Pro . 2022-03-04 16:00:00.800254: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support. 2022-03-04 16:00:00.800357: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -&gt; physical PluggableDevice (device: 0, name: METAL, pci bus id: &lt;undefined&gt;) . What is the number of parameters in the above FCNN architecture? . FCNN.summary() . Model: &#34;sequential&#34; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= hidden_layer (Dense) (None, 4) 16388 Classification_output_layer (None, 1) 5 (Dense) ================================================================= Total params: 16,393 Trainable params: 16,393 Non-trainable params: 0 _________________________________________________________________ . history = FCNN.fit(X_flat, Y, epochs=20, batch_size=5, verbose=0) . 2022-03-04 16:00:00.881198: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz 2022-03-04 16:00:01.041286: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled. . score = FCNN.evaluate(X_flat, Y, verbose=0) print(&#39;Train loss:&#39;, score[0]) print(&#39;Train accuracy:&#39;, score[1]) . Train loss: 0.6931478381156921 Train accuracy: 0.5 . 2022-03-04 16:00:01.516562: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled. . II. Classification with a CNN . Task #2: Build a CNN with one convolutional layer, one maxpooling layer and one dense layer to classify the face images. What are some theoretical strengths and drawbacks of using CNN versus MLP for handling image data? . Kernel Size, Stride Size and number of filters for Conv2D layer is specified as below. The activation function is relu | The pooling size is 4 by 4 for maxpooling Layer | Other hyper-parameters in neural networks are set to be default. . kernel_size = (8, 8) # stride size stride_size = (1, 1) # number of filters filters = 4 cnn_model = Sequential() cnn_model.add(Input(shape=(64, 64, 1))) # feature extraction layer 0: convolution cnn_model.add(Conv2D(filters, kernel_size=kernel_size, activation=&#39;relu&#39;, strides=stride_size)) # feature extraction layer 1: max pooling cnn_model.add(MaxPooling2D(pool_size=(4,4))) # classification layer 2: flattening cnn_model.add(Flatten()) # classification layer 3: dense non-linear transformation cnn_model.add(Dense(4, activation=&#39;relu&#39;, name=&#39;Relu_Non_linear&#39;)) # classification layer 4: output label probability cnn_model.add(Dense(1, activation=&#39;sigmoid&#39;, name = &#39;Output_label_probability&#39;)) # configure the model cnn_model.compile(loss=&#39;binary_crossentropy&#39;, metrics=[&#39;accuracy&#39;]) . What is the number of parameters in the above CNN architecture. And compare the model size with the FCNN model size . cnn_model.summary() . Model: &#34;sequential_1&#34; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= conv2d (Conv2D) (None, 57, 57, 4) 260 max_pooling2d (MaxPooling2D (None, 14, 14, 4) 0 ) flatten (Flatten) (None, 784) 0 Relu_Non_linear (Dense) (None, 4) 3140 Output_label_probability (D (None, 1) 5 ense) ================================================================= Total params: 3,405 Trainable params: 3,405 Non-trainable params: 0 _________________________________________________________________ . Compare the CNN model size with the FCNN model size . FCNN Model total parameters = 16,393. . Let&#39;s interpret this parameter size. For each face image with (64 x 64 x 1) pixels in grayscale equal to (64 x 64 x 1) weights are needed by every hidden layer along with 4 bias terms, 1 term for each layer, i.e. ((64 x 64 x 1) x 4) + 4 = 16,388 weight parameters are needed by the FCNN model hidden layers alone. | . CNN Model total parameters = 3,405 . Convolution Layer has 4 filter kernels with dimensions (8 x 8) each, that perform convolution operation with same size (8 x 8) sub grid of input image of dimensions(64 x 64 x 1) and move 1 stride in each iteration, first horizontally then vertically. This results into a smaller size output of dimension (57 x 57) each for 4 filters. Activation function &#39;relu&#39; only gives outputs that are greater than 0. The (8 x 8) filter grid produces 64 weight paramters each for 4 filters that result into 256 weights and 4 bias terms(for 4 filter kernels) leading to 260 total weights in the convolution layer. | MaxPooling2D Layer has a pool_size of (4 x 4) which means that for every (4 x 4) sub-matrix moving with 1 stride on (57 x 57) image output of convoliton layer a maximum value from these 4 values will be resulting into output of this layer. This will reduce the convoluted image into (14 x 14) image output for each of the 4 filters and no weights as parameters. | These (14 x 14 x 4) are flattened into a single vector array with 784 values | This flattened array passes through 4 hidden layers producing (784 x 4 = 3136) weights and 1 bias terms for each of the 4 layers resulting into 3140 paramters. | . We can conclude that the number of model parameters is significantly reduced due to convolution layer and size of input image is further reduced by max_pooling layer according to pool_size. In this way the hidden layer receives only 784 values for creating the fully connected network to extract features. CNN requires very less parameters as compared to FCNN model, we can conclude that CNN is more efficient than FCNN for image feature extraction tasks. . history = cnn_model.fit(X, Y, epochs=20, batch_size=5, verbose=0) . 2022-03-04 16:00:01.778287: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled. . # note: you should extract check both the loss function and your evaluation metric score = cnn_model.evaluate(X, Y, verbose=0) print(&#39;Train loss:&#39;, score[0]) print(&#39;Train accuracy:&#39;, score[1]) . Train loss: 0.5172786116600037 Train accuracy: 1.0 . 2022-03-04 16:00:02.361107: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled. . You should find the CNN model size is smaller than the FCNN model size while FCNN&#39;s training accuracy is much lower than CNN&#39;s training accuracy. Is it due to overfitting? If not, pls explain . . FCNN network with large number of parameters(16k) can face several problems such as overfitting, slower speed of training, capturing patterns globally and not locally, because in FCNN a single network is responsible for feature extractor of whole image. Due to this, FCNN fails at recognizing same/similar patterns at different locations as it might becomes location sensitive. . We must note that for image data analysis - local features matter and they are significantly very important. . CNN allows us to focus on capturing discriminative smaller sub-patterns that make model capable to differentiate between 2 and more faces. The CNN trained model is now capable to implement it&#39;s learnings on test data while performing classification operation. CNN allows to establish multiple networks of neurons for feature extraction wherein parameters such as filters, strides_size and pooling layers facilitate a smaller and optimum number of model parameters to capture local patterns for differentiation and lead to more efficiency, flexibility in learning and performance accuracy. Also, major advantage is that, in CNN small network neurons remain insensitive to location of patterns. Thus, when same/similar patterns appear in different regions of different images CNN performs well in identifying these local patterns. . III What Exactly Does a CNN Learn? . A Multi-Layer Perceptron (MLP) trained for classification learns a non-linear transformation of the data so that the classes are linearly separable. Here, we could try to get an intuitive understanding of what is the transformation learned from each hidden layer in a CNN. . Task #3: Let&#39;s visualize the weights connecting the input image to each kernel in the convolutional layer, these are called &#39;filters&#39;. Explain how each filter is applied to the input image. . # we plot two sample images from the data set fig, ax = plt.subplots(1, 2, figsize=(10, 5)) ax[0] = plot_face(ax[0], X[Y == 0][0], image_shape) ax[1] = plot_face(ax[1], X[Y == 1][0], image_shape) plt.show() # using plot_face() function to visualize the four (8,8) filters cnn_model learned fig, ax = plt.subplots(1, 4, figsize=(10, 5)) ax[0] = plot_face(ax[0], cnn_model.layers[0].get_weights()[0][:, :, :, 0].flatten(), (8, 8)) ax[1] = plot_face(ax[1], cnn_model.layers[0].get_weights()[0][:, :, :, 1].flatten(), (8, 8)) ax[2] = plot_face(ax[2], cnn_model.layers[0].get_weights()[0][:, :, :, 2].flatten(), (8, 8)) ax[3] = plot_face(ax[3], cnn_model.layers[0].get_weights()[0][:, :, :, 3].flatten(), (8, 8)) plt.show() . Explain how each filter is applied to the input image . Each (8 x 8) kernel performs convolution operation with smaller (8 x 8) sub-grids of input face image. As a result of this dot product operation, 4 feature Maps are created for 4 different kernels. To understand visually, we can say that the each (8 x 8) kernel moves first horizontally and then vertically on top of (8 x 8) subgrids of each (64 x 64 x 1) face image with 1 step stride size to produce a convolved image of (57 x 57). The 4 kernels with different weights perform the same dot product operation on input face image to produce these resultant 4 feature Maps. . Task #4: visualize the output of the convolutional layer and the pooling layer separately. Describe how each layer has transformed the data. . # using the backend.function in keras from tensorflow.keras import backend face_0 = X[Y == 0][0] get_conv_layer_output = backend.function([cnn_model.layers[0].input], [cnn_model.layers[0].output]) layer_output = get_conv_layer_output(np.expand_dims(face_0, axis=0))[0] . conv_output_img_shape = (57,57) fig, ax = plt.subplots(1, 4, figsize=(10, 5)) ax[0] = plot_face(ax[0], layer_output[:, :, :, 0].flatten(), conv_output_img_shape) ax[1] = plot_face(ax[1], layer_output[:, :, :, 1].flatten(), conv_output_img_shape) ax[2] = plot_face(ax[2], layer_output[:, :, :, 2].flatten(), conv_output_img_shape) ax[3] = plot_face(ax[3], layer_output[:, :, :, 3].flatten(), conv_output_img_shape) plt.show() . get_pool_layer_output = backend.function([cnn_model.layers[0].input], [cnn_model.layers[1].output]) pool_output = get_pool_layer_output(np.expand_dims(face_0, axis=0))[0] . maxp_output_img_shape = (14,14) fig, ax = plt.subplots(1, 4, figsize=(10, 5)) ax[0] = plot_face(ax[0], pool_output[:, :, :, 0].flatten(), maxp_output_img_shape) ax[1] = plot_face(ax[1], pool_output[:, :, :, 1].flatten(), maxp_output_img_shape) ax[2] = plot_face(ax[2], pool_output[:, :, :, 2].flatten(), maxp_output_img_shape) ax[3] = plot_face(ax[3], pool_output[:, :, :, 3].flatten(), maxp_output_img_shape) plt.show() . Describe how each layer has transformed the data. . In Convolution Layer has 4 filter kernels with dimensions (8 x 8) each, that perform convolution operation with same size (8 x 8) sub grid of input image of dimensions (64 x 64) and move 1 stride in each iteration, first horizontally then vertically. Sum of dot products of corresponding elements is the output of this layer. This results into a smaller size output of dimension (57 x 57) each for 4 filters which has been visualized as the output of the convolution layer. The non-linear activation function &#39;relu&#39; gives outputs that are greater than 0. | MaxPooling2D Layer has a pool_size of (4 x 4) which means that for every (4 x 4) sub-matrix moving with 1 stride on (57 x 57) image output of convoliton layer a maximum value from these 4 elements will be resulting into output of this layer. This will reduce the convoluted image from (57 x 57) into (14 x 14) image output for each of the 4 filter kernels. | These (14 x 14 x 4) are flattened into a single vector array with 784 values which passes through 4 hidden layers that are able to learn features and representations through a connected neural network. The classifier can then recognize these sub-patterns in more faces images dataset. | . Recommended: . To visually and theoretically understand working of CNN would recommend to read Convolution Neural Networks vs Fully Connected Neural Networks | .",
            "url": "https://contactmansi.github.io/workoutdata/image-analytics/cnn/classification/fully%20connected/convolutional%20neural%20network/faces-dataset/2022/03/03/CNN-based-face-image-classifier.html",
            "relUrl": "/image-analytics/cnn/classification/fully%20connected/convolutional%20neural%20network/faces-dataset/2022/03/03/CNN-based-face-image-classifier.html",
            "date": " • Mar 3, 2022"
        }
        
    
  
    
        ,"post4": {
            "title": "Setup Virtual Environment in Jupyter Notebook",
            "content": "To use virtual environments with jupyter notebook, best practice is to create an independent virtual environment and add it to jupyter notebook as a kernel. This provides the portability to use the same venv on other IDEs or commandline as well as remove the venv from jupyter notebook incase it is no longer required and delete the venv. Let’s dive into creating and setting up a new ven on jupyter notebook in windoes system. Recommended to create and add new venvs for each python project so that each project’s dependencies can be safely isolated from others to avoid conflicts. . Jupyter notebook handles venvs as kernels. These kernels can be added to existing jupyter notebook by installing ipykernel library on venv and installing the venv as new kernel to existing jupyter notebook installation. Follow the steps below by updating the command format as per your OS and commandline. . OBJECTIVE . Create &amp; activate New Virtual Environment on Windows local system using virtualenv wrapper | Add Virtual Environment Kernel to jupyter notebook | Activate New virtual environment Kernel in jupyterbook using ‘Change Kernel’ | Remove/Delete a kernel from jupyter notebook | 1. CREATE &amp; ACTIVATE NEW VIRTUAL ENVIRONMENT ON WINDOWS SYSTEM . NOTE: All commands are based on Windows PowerShell 2. Please follow the steps by changing command formats accordingly for your commandline tool and OS. . Navigate to directory where you new virtual environment is to be created . cd Replace_this_with path_to_directory for_new_venv . Create new folder where environment will be saved such as venv_project_name . mkdir venv_NEW_DIRECTORY_NAME . Navigate into new directory . cd . venv_NEW_DIRECTORY_NAME . Create New Virtual Environment Using Virtualenv Wrapper . Choose Any Suitable Virtual Environment Name Such As virtual_env_name | Providing path to python installation is optional. Use any one command below: virtualenv virtual_env_name virtualenv virtual_env_name -p C:/ProgramData/Anaconda3/python.exe . | . Activate New Virtual Environment for windows . ./virtual_env_name/Scripts/activate . Alternatively Activate New Virtual Environment for macOS . source ./virtual_env_name/bin/activate . 2. ADD VIRTUAL ENVIRONMENT KERNEL TO JUPYTER NOTEBOOK . Intsall ipykernel in New Virtual Environment . pip install ipykernel . Add New Venv as ipykernel to Jupyter Notebook &amp; list all ipykernels . python -m ipykernel install --name=virtual_env_name jupyter kernelspec list . 3. ACTIVATE NEW VIRUAL ENVIRONMENT OR KERNEL IN JUPYTER NOTEBOOK . Launch jupyter notebook through commandline using jupyter notebook command | Open a new notebook | Alternatively, if jupyter notebook is already running then refresh/reload browser | In the Menu bar navigate to Kernel –&gt; Change Kernel –&gt; Select virtual_env_name (name of the newly created and added virtual environment) | Observe Kernel name on the top right change from Python 3 to virtual_env_name | . Congrats! New Virtual Environment Kernel is now actiavted in Jupyter notebook . For using an existing kernel already added to jupyter notebook only navigate to Kernel –&gt; Change Kernel –&gt; Select virtual_env_name | There is no need to activate virtual environment in command prompt or terminal to use the kernel in jupyter notebook. The terminal for jupyter notebook will shutdown the running Python 3 Kernel and activated the selected virtual_env_name kernel | To install pip packages activate virtual environment on commandline and install packages using pip install package_name as usual on commandline | . 4. DELETE KERNEL FROM JUPYTER NOTEBOOK . List all kernels to copy name of kernel to be removed . jupyter kernelspec list . Remove kernel using unistall . jupyter kernelspec uninstall unwanted_kernel_name .",
            "url": "https://contactmansi.github.io/workoutdata/markdown/2022/01/29/Virtual-Environment-Jupyter-Notebook.html",
            "relUrl": "/markdown/2022/01/29/Virtual-Environment-Jupyter-Notebook.html",
            "date": " • Jan 29, 2022"
        }
        
    
  
    
        ,"post5": {
            "title": "Cost Cutting In Human Resource Management Through Employee Churn Prediction",
            "content": "Why Attrition is a Problem? . Companies invest quantifiably large sums of money and effort in hiring and this includes releasing and posting openings, paying recruiters, screening and interviewing candidates. Firms start earning their return on investment when a new hire starts to deliver functional and business requirements which take at least a couple of months. . Attrition refers to the number of people who stop working due to resignation, retirement, or death. Attrition can take various forms but generally for most companies, two types are most common namely employee departure and employee retirement. Employees nowadays are more eager than ever before to jump from one business to another in search of better opportunities. Employee churn has become a major issue in most businesses since there has been a significant increase in staff turnover. . Import Libraries and modules . import math import time import copy import warnings import numpy as np import pandas as pd import matplotlib.pyplot as plt import seaborn as sns import plotly.offline as py import plotly.graph_objs as go import plotly.tools as tls import plotly.figure_factory as ff from plotnine import * from scipy import stats from sklearn.linear_model import LogisticRegression from sklearn.tree import DecisionTreeClassifier from sklearn.ensemble import RandomForestClassifier from sklearn.model_selection import train_test_split, cross_val_score, KFold from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_error, accuracy_score from sklearn.metrics import accuracy_score, confusion_matrix,roc_curve, roc_auc_score, precision_score, recall_score, precision_recall_curve, classification_report from sklearn.preprocessing import StandardScaler, LabelEncoder, scale from sklearn_pandas import DataFrameMapper, gen_features, cross_validation from sklearn.decomposition import PCA from imblearn.over_sampling import SMOTE from IPython.core.display import display, HTML # settings: display(HTML(&quot;&lt;style&gt;.container { width:100% !important; }&lt;/style&gt;&quot;)) pd.options.display.max_columns = 100 pd.options.display.max_rows = 1000 plt.rcParams[&#39;font.family&#39;] = &#39;DejaVu Sans&#39; plt.rcParams[&#39;axes.unicode_minus&#39;]=False plt.style.use(&#39;ggplot&#39;) psd = lambda q: sqldf(q, gloabls()) py.init_notebook_mode(connected=True) warnings.filterwarnings(&#39;ignore&#39;) . . /var/folders/_0/n4532gdd0lzfngk_qy30wzc00000gq/T/ipykernel_50640/4217177242.py:30: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display . Data Overview through Exploratory Data Analysis (EDA) . Displaying a couple of records to ghet a fair idea of how the dataset looks. It is most important to understand the numeric and categorical columns in any dataset. Let&#39;s also check for missing values for all columns/features. In case there are a lot of missing values we might need to employ missing values treatment as a part of data preprocessing. Information shows that this dataset does not contain any Null values. . data = pd.read_csv(&#39;../data/employee_attrition_ibm_data.csv&#39;, index_col=&#39;EmployeeNumber&#39;) print(f&quot;This data has {data.shape[0]} employees with {data.shape[1]} features for each employee as follows&quot;) display(data.head(5)) . . This data has 1470 employees with 34 features for each employee as follows . Age Attrition BusinessTravel DailyRate Department DistanceFromHome Education EducationField EmployeeCount EnvironmentSatisfaction Gender HourlyRate JobInvolvement JobLevel JobRole JobSatisfaction MaritalStatus MonthlyIncome MonthlyRate NumCompaniesWorked Over18 OverTime PercentSalaryHike PerformanceRating RelationshipSatisfaction StandardHours StockOptionLevel TotalWorkingYears TrainingTimesLastYear WorkLifeBalance YearsAtCompany YearsInCurrentRole YearsSinceLastPromotion YearsWithCurrManager . EmployeeNumber . 1 41 | Yes | Travel_Rarely | 1102 | Sales | 1 | 2 | Life Sciences | 1 | 2 | Female | 94 | 3 | 2 | Sales Executive | 4 | Single | 5993 | 19479 | 8 | Y | Yes | 11 | 3 | 1 | 80 | 0 | 8 | 0 | 1 | 6 | 4 | 0 | 5 | . 2 49 | No | Travel_Frequently | 279 | Research &amp; Development | 8 | 1 | Life Sciences | 1 | 3 | Male | 61 | 2 | 2 | Research Scientist | 2 | Married | 5130 | 24907 | 1 | Y | No | 23 | 4 | 4 | 80 | 1 | 10 | 3 | 3 | 10 | 7 | 1 | 7 | . 4 37 | Yes | Travel_Rarely | 1373 | Research &amp; Development | 2 | 2 | Other | 1 | 4 | Male | 92 | 2 | 1 | Laboratory Technician | 3 | Single | 2090 | 2396 | 6 | Y | Yes | 15 | 3 | 2 | 80 | 0 | 7 | 3 | 3 | 0 | 0 | 0 | 0 | . 5 33 | No | Travel_Frequently | 1392 | Research &amp; Development | 3 | 4 | Life Sciences | 1 | 4 | Female | 56 | 3 | 1 | Research Scientist | 3 | Married | 2909 | 23159 | 1 | Y | Yes | 11 | 3 | 3 | 80 | 0 | 8 | 3 | 3 | 8 | 7 | 3 | 0 | . 7 27 | No | Travel_Rarely | 591 | Research &amp; Development | 2 | 1 | Medical | 1 | 1 | Male | 40 | 3 | 1 | Laboratory Technician | 2 | Married | 3468 | 16632 | 9 | Y | No | 12 | 3 | 4 | 80 | 1 | 6 | 3 | 3 | 2 | 2 | 2 | 2 | . A general statistical descrition of data in all features can help us understand the distribution for each numeric feature. . data.describe(include=&#39;all&#39;) . . Age Attrition BusinessTravel DailyRate Department DistanceFromHome Education EducationField EmployeeCount EnvironmentSatisfaction Gender HourlyRate JobInvolvement JobLevel JobRole JobSatisfaction MaritalStatus MonthlyIncome MonthlyRate NumCompaniesWorked Over18 OverTime PercentSalaryHike PerformanceRating RelationshipSatisfaction StandardHours StockOptionLevel TotalWorkingYears TrainingTimesLastYear WorkLifeBalance YearsAtCompany YearsInCurrentRole YearsSinceLastPromotion YearsWithCurrManager . count 1470.000000 | 1470 | 1470 | 1470.000000 | 1470 | 1470.000000 | 1470.000000 | 1470 | 1470.0 | 1470.000000 | 1470 | 1470.000000 | 1470.000000 | 1470.000000 | 1470 | 1470.000000 | 1470 | 1470.000000 | 1470.000000 | 1470.000000 | 1470 | 1470 | 1470.000000 | 1470.000000 | 1470.000000 | 1470.0 | 1470.000000 | 1470.000000 | 1470.000000 | 1470.000000 | 1470.000000 | 1470.000000 | 1470.000000 | 1470.000000 | . unique NaN | 2 | 3 | NaN | 3 | NaN | NaN | 6 | NaN | NaN | 2 | NaN | NaN | NaN | 9 | NaN | 3 | NaN | NaN | NaN | 1 | 2 | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | . top NaN | No | Travel_Rarely | NaN | Research &amp; Development | NaN | NaN | Life Sciences | NaN | NaN | Male | NaN | NaN | NaN | Sales Executive | NaN | Married | NaN | NaN | NaN | Y | No | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | . freq NaN | 1233 | 1043 | NaN | 961 | NaN | NaN | 606 | NaN | NaN | 882 | NaN | NaN | NaN | 326 | NaN | 673 | NaN | NaN | NaN | 1470 | 1054 | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | . mean 36.923810 | NaN | NaN | 802.485714 | NaN | 9.192517 | 2.912925 | NaN | 1.0 | 2.721769 | NaN | 65.891156 | 2.729932 | 2.063946 | NaN | 2.728571 | NaN | 6502.931293 | 14313.103401 | 2.693197 | NaN | NaN | 15.209524 | 3.153741 | 2.712245 | 80.0 | 0.793878 | 11.279592 | 2.799320 | 2.761224 | 7.008163 | 4.229252 | 2.187755 | 4.123129 | . std 9.135373 | NaN | NaN | 403.509100 | NaN | 8.106864 | 1.024165 | NaN | 0.0 | 1.093082 | NaN | 20.329428 | 0.711561 | 1.106940 | NaN | 1.102846 | NaN | 4707.956783 | 7117.786044 | 2.498009 | NaN | NaN | 3.659938 | 0.360824 | 1.081209 | 0.0 | 0.852077 | 7.780782 | 1.289271 | 0.706476 | 6.126525 | 3.623137 | 3.222430 | 3.568136 | . min 18.000000 | NaN | NaN | 102.000000 | NaN | 1.000000 | 1.000000 | NaN | 1.0 | 1.000000 | NaN | 30.000000 | 1.000000 | 1.000000 | NaN | 1.000000 | NaN | 1009.000000 | 2094.000000 | 0.000000 | NaN | NaN | 11.000000 | 3.000000 | 1.000000 | 80.0 | 0.000000 | 0.000000 | 0.000000 | 1.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | . 25% 30.000000 | NaN | NaN | 465.000000 | NaN | 2.000000 | 2.000000 | NaN | 1.0 | 2.000000 | NaN | 48.000000 | 2.000000 | 1.000000 | NaN | 2.000000 | NaN | 2911.000000 | 8047.000000 | 1.000000 | NaN | NaN | 12.000000 | 3.000000 | 2.000000 | 80.0 | 0.000000 | 6.000000 | 2.000000 | 2.000000 | 3.000000 | 2.000000 | 0.000000 | 2.000000 | . 50% 36.000000 | NaN | NaN | 802.000000 | NaN | 7.000000 | 3.000000 | NaN | 1.0 | 3.000000 | NaN | 66.000000 | 3.000000 | 2.000000 | NaN | 3.000000 | NaN | 4919.000000 | 14235.500000 | 2.000000 | NaN | NaN | 14.000000 | 3.000000 | 3.000000 | 80.0 | 1.000000 | 10.000000 | 3.000000 | 3.000000 | 5.000000 | 3.000000 | 1.000000 | 3.000000 | . 75% 43.000000 | NaN | NaN | 1157.000000 | NaN | 14.000000 | 4.000000 | NaN | 1.0 | 4.000000 | NaN | 83.750000 | 3.000000 | 3.000000 | NaN | 4.000000 | NaN | 8379.000000 | 20461.500000 | 4.000000 | NaN | NaN | 18.000000 | 3.000000 | 4.000000 | 80.0 | 1.000000 | 15.000000 | 3.000000 | 3.000000 | 9.000000 | 7.000000 | 3.000000 | 7.000000 | . max 60.000000 | NaN | NaN | 1499.000000 | NaN | 29.000000 | 5.000000 | NaN | 1.0 | 4.000000 | NaN | 100.000000 | 4.000000 | 5.000000 | NaN | 4.000000 | NaN | 19999.000000 | 26999.000000 | 9.000000 | NaN | NaN | 25.000000 | 4.000000 | 4.000000 | 80.0 | 3.000000 | 40.000000 | 6.000000 | 4.000000 | 40.000000 | 18.000000 | 15.000000 | 17.000000 | . Target variable : Attrition Label Count . data.Attrition.value_counts().plot(kind=&#39;bar&#39;) plt.figure(figsize=(20,8)) data[&#39;Attrition&#39;].value_counts().plot(kind=&#39;pie&#39;,explode=[0.1,0.1],autopct=&#39;%1.1f%%&#39;,shadow=True,colors=[&#39;c&#39;,&#39;r&#39;]) print(data[&#39;Attrition&#39;].value_counts()) . . No 1233 Yes 237 Name: Attrition, dtype: int64 . Summary: . Dataset Structure: 1470 observations (rows), 35 features (variables) | Missing Data: no missing data! this will make it easier to work with the dataset. | Data Type: We only have two datatypes in this dataset: categorical and integers | Label&quot; Attrition is the label in our dataset and we would like to find out why employees are leaving the organization! | Imbalanced dataset: 1237 (84% of cases) employees did not leave the organization while 237 (16% of cases) left the organization making our dataset to be considered imbalanced since more people stay in the organization than they actually leave. | . Exploratory Data Analysis . Correlation between Attrtion and Features . # Subset the dataset into all the numerical values numeric_hr = data.select_dtypes(include=[np.number]) # Compete the correlation matrix corr = numeric_hr._get_numeric_data().corr() # Generate a mask for the upper triangle mask = np.zeros_like(corr, dtype=np.bool) mask[np.triu_indices_from(mask)] = True # Set up the matplotlib figure f, ax = plt.subplots(figsize=(19, 15)) # Draw the heatmap with the mask and correct aspect ratio heatmap = sns.heatmap(corr, mask=mask, center=0.0, annot=True, annot_kws={&quot;size&quot;: 8}, # cmap=cmap, vmax = 1, square=True, linewidths=.5, ax=ax) plt.show() . . Interpretations: . Age: -0.15 ~ With increase in age less likely to attrition ~ which is reasonable | DailyRate: -0.0056 ~ With increase in DailyRate attrition decreases ~ which is reasonable | DistanceFromHome: 0.077 ~ With increase in DistanceFromHome attrition is more likely ~ which is reasonable | Education: -0.031 ~ With higher level of education, attrition becomes less likely ~ which is reasonable | EnvironmentSatisfaction: -0.103 ~ With higher level of EnvironmentSatisfaction, attrition becomes less likely ~ which is reasonable | NumCompaniesWorked : 0.043494 ~ With increase in NumCompaniesWorked, more likely to attrition --&gt; reflects tendency to switch more jobs | . &#39;&#39;&#39;Setting default layouts for all plots&#39;&#39;&#39; # setting a default figure size fig_size = plt.rcParams[&quot;figure.figsize&quot;] fig_size[0] = 10 fig_size[1] = 6 plt.rcParams[&quot;figure.figsize&quot;] = fig_size # setting a default style sns.set_style(&#39;darkgrid&#39;) # setting tight layout plt.figure(tight_layout=True) # setting a default font sixe for labels sns.set_context(&quot;paper&quot;, font_scale=1) . . &lt;Figure size 720x432 with 0 Axes&gt; . Income vs Attrition: . Average Income by Departments . Q. What is the average monthly income by department? Are there any significant differences between individuals who quit and didn&#39;t quit? . People with lower salaries had more attrition rate than the one’s being paid well | . # Plot Option 1 plt.title(&#39;Average Income by Department and Attrition Status&#39;, size=18) plots = sns.barplot(x=&quot;Attrition&quot;, y=&quot;MonthlyIncome&quot;, hue=&quot;Department&quot;, order = [&#39;No&#39;,&#39;Yes&#39;],data = data, palette = &#39;magma&#39;, ci=None) for container in plots.containers: plt.bar_label(container) plt.xlabel(&quot;Department&quot;, size=14) plt.ylabel(&quot;Average Income&quot;, size=14) plt.show() . . Determining Job Satisfaction by Income . Q Are there significant changes in the level of income by Job Satisfaction? Are individuals with a lower satisfaction getting much less income than the ones who are more satisfied? . It seems the lower the job satisfaction the wider the gap by attrition status in the levels of income. | . # Plot Option 1: Q2: Is Income a reason for lower Job Satisfaction? sns.set_style(&#39;darkgrid&#39;) plt.figure(figsize = (10, 6), tight_layout=True) plt.title(&#39;Is Income a reason for lower Job Satisfaction?&#39;, size=18) plots = sns.barplot(y=&quot;MonthlyIncome&quot;, x=&quot;JobSatisfaction&quot;, hue=&quot;Attrition&quot;, data=data, palette = &#39;magma&#39;, estimator=np.median, ci=None) for container in plots.containers: plt.bar_label(container) plt.xlabel(&quot;Job Satisfaction&quot;, size=14) plt.ylabel(&quot;Median Income&quot;, size=14) plt.show() . . YearsInCurrentRole vs Attrition . Q. What is the trend of Attrition with respect to the number of years spent in a current role? How is Monthly income distributed among these years? . The count plot very well reflects the typical tendency of newly recruited professionals, with under 4 years in current roles, to switch jobs frequently if the role is unsatisfactory or for monetary growth until they find stability. | Note that there is a hike in attrition among employees with 7,8,9 years of experience which amounts to approximately 21.5% of the total attrition rate in the organisation. | The box plot very interestingly highlights that employees with 6 years into their current role are earning more than 13, 14 years into the current role. | From these two plots together, we can infer that attrition seems to increase gradually when the monthly income decreases beyond 6 years. T | . # sns.set_context(&quot;paper&quot;, font_scale=0.9) sns.set_context(&quot;paper&quot;, rc={&quot;font.size&quot;:18,&quot;axes.titlesize&quot;:16,&quot;axes.labelsize&quot;:16}) plt.figure(figsize=(15,14)) plt.subplot(211) plt.title(&#39;YearsInCurrentRole Vs Attrition&#39;,fontsize = 18) sns.countplot(data[&#39;YearsInCurrentRole&#39;],hue=data[&#39;Attrition&#39;],palette=&#39;magma&#39;) plt.subplot(212) plt.title(&#39;YearsInCurrentRole Vs MonthlyIncome&#39;) sns.boxplot(data[&#39;YearsInCurrentRole&#39;],data[&#39;MonthlyIncome&#39;]) # plt.savefig(&#39;YearsIncurrentrole.png&#39;,dpi=300) . . &lt;AxesSubplot:title={&#39;center&#39;:&#39;YearsInCurrentRole Vs MonthlyIncome&#39;}, xlabel=&#39;YearsInCurrentRole&#39;, ylabel=&#39;MonthlyIncome&#39;&gt; . Satisfaction Levels vs Attrition . EnvironmentSatisfaction by Job Roles vs Attrition . Q. Which Job Roles has lowest olevels of Environment Satisfaction? Was low environment satisfaction a significant reason for attrition?** . EnvironmentSatisfaction by Job Roles: Managers and healthcare representatives operate in a less stressful atmosphere than sales representatives, which may be due to the fact that most sales representatives work outside the firm. | . daily_r = data[[&#39;JobRole&#39;, &#39;Attrition&#39;, &#39;EnvironmentSatisfaction&#39;]] gp = ggplot(daily_r, aes( x=&#39;JobRole&#39;, y=&#39;EnvironmentSatisfaction&#39;, color=&#39;Attrition&#39;)) + facet_wrap([&#39;Attrition&#39;]) + coord_flip() + theme_seaborn() + theme( axis_text_x = element_text(angle=90), plot_title=element_text(hjust=0.5, size=16), plot_background=element_rect(fill=&#39;#FFF1E0&#39;), figure_size=(10, 4)) + stat_summary( fun_y = np.mean, fun_ymin=np.min, fun_ymax=np.max) + scale_color_manual(values=[&quot;#58FA58&quot;, &quot;#FA5858&quot;]) + labs(title=&quot;Environment Satisfaction by Job Role&quot;) gp . . &lt;ggplot: (-9223371905573307784)&gt; . Relationship Satisfaction by Gender vs Attrition . Q. Does relationship satisfaction affect males and females differently with regards to job attrition? . Relationship Satisfaction by Gender: People who did not undergo attrition seemed to enjoy higher levels of relationship satisfaction. Among those who underwent attrition, females tended to have lower levels of relationship satisfaction. | . plt.figure(figsize = (10, 6), tight_layout=True) plt.title(&#39;Relationship Satisfaction by Gender and Attrition Status&#39;, size=18) plots = sns.barplot(x=&quot;Attrition&quot;, y=&quot;RelationshipSatisfaction&quot;, hue=&quot;Gender&quot;, order = [&#39;Yes&#39;,&#39;No&#39;], data=data, palette = &#39;magma&#39;, ci=None) for container in plots.containers: plt.bar_label(container) plt.xlabel(&quot;Attrition Status&quot;, size=14) plt.ylabel(&quot;Relationship Satisfaction&quot;, size=14) plt.show() . . YearsWithCurrManager with JobSatisfaction vs Attrition . Q. Were employees more likely to leave their jobs if they spent more time with the same manager? . Employees who undergo attrititon don&#39;t spend more than 2 years with the same manager, irregardless of job satisfaction | . # ManagerExperience + JobSatisfaction plt.title(&#39;Job satisfaction &amp; Years with current manager&#39;, size=18) plots = sns.barplot(x=&quot;Attrition&quot;, y=&quot;YearsWithCurrManager&quot;, hue=&quot;JobSatisfaction&quot;, data=data, estimator=np.median, palette = &#39;Set2&#39;, ci=None) # for container in plots.containers: # plt.bar_label(container) for bar in plots.patches: plots.annotate(format(bar.get_height(), &#39;.2f&#39;), (bar.get_x() + bar.get_width() / 2, bar.get_height()), ha=&#39;center&#39;, va=&#39;center&#39;, size=15, xytext=(0, 8), textcoords=&#39;offset points&#39;) plt.xlabel(&quot;Attrition Status&quot;, size=14) plt.ylabel(&quot;Years with current manager&quot;, size=14) plt.show() . . OverTime vs Attrition . Q. How does exhaustion contribute to attrition? . Generally, those who stayed further from home were more likely to undergo attrition. The rate of attrition is especially high among those who worked from home and also worked overtime. This group most likely resigned due to the severe lack of personal time since most of their time is spent working or travelling to work and are probably very exhausted. | . plt.title(&#39;Overtime by Distance From Home and Attrition Status&#39;, size=18) plots = sns.barplot(x=&quot;Attrition&quot;, y=&quot;DistanceFromHome&quot;, hue=&quot;OverTime&quot;, order = [&#39;No&#39;,&#39;Yes&#39;],data=data, palette = &#39;magma&#39;, ci=None) for container in plots.containers: plt.bar_label(container) plt.xlabel(&quot;Attrition Status&quot;, size=14) plt.ylabel(&quot;Distance From Home&quot;, size=14) plt.show() . . Feature Selection and Engineering . Analysing for different groups of age . agebins=pd.cut(data[&#39;Age&#39;],bins=[15,20,25,30,35,40,45,50,55,60]) #Discretisation to understand what age categories to Target plt.figure(figsize=(15,5)) plt.title(&#39;Distribution of Age&#39;,size=15) sns.distplot(data[&#39;Age&#39;],bins=[15,20,25,30,35,40,45,50,55,60],color=&#39;c&#39;) plt.figure(figsize=(15,5)) plt.title(&#39;Age Wise Binning wrt Attrition&#39;,size=15) sns.countplot(agebins, hue=&#39;Attrition&#39;,data=data,palette=&#39;CMRmap_r&#39;) . . &lt;AxesSubplot:title={&#39;center&#39;:&#39;Age Wise Binning wrt Attrition&#39;}, xlabel=&#39;Age&#39;, ylabel=&#39;count&#39;&gt; . Data Processing and Feature Engineering . # Reassign target data.Attrition.replace(to_replace = dict(Yes = 1, No = 0), inplace = True) # Find &amp; Delete the useless features li_useless_feat = [] for col in list(data.columns): if data[col].nunique() == 1: li_useless_feat.append(col) print(&#39;Useless Features:{}&#39;.format(li_useless_feat)) data.drop(columns=li_useless_feat, inplace=True) # generation-related functions def age_to_born_yyyy(x): return 2015 - x def cat_generation(x): if (x&gt;=1940) &amp; (x&lt;=1959): return &#39;gen_baby_boomer&#39; elif (x&gt;=1960) &amp; (x&lt;=1979): return &#39;gen_x&#39; elif (x&gt;=1980) &amp; (x&lt;=1994): return &#39;gen_y&#39; elif (x&gt;=1995) &amp; (x&lt;=2010): return &#39;gen_z&#39; else: return &#39;gen_alpha&#39; # Add generation-related columns data[&#39;born_yyyy&#39;] = data.Age.apply(age_to_born_yyyy) data[&#39;generation&#39;] = data.born_yyyy.apply(cat_generation) display( np.round(data.generation.value_counts()/len(data)*100, 2), data.shape, data.head() ) . . Useless Features:[&#39;EmployeeCount&#39;, &#39;Over18&#39;, &#39;StandardHours&#39;] . gen_y 47.69 gen_x 47.21 gen_baby_boomer 3.20 gen_z 1.90 Name: generation, dtype: float64 . (1470, 33) . Age Attrition BusinessTravel DailyRate Department DistanceFromHome Education EducationField EnvironmentSatisfaction Gender HourlyRate JobInvolvement JobLevel JobRole JobSatisfaction MaritalStatus MonthlyIncome MonthlyRate NumCompaniesWorked OverTime PercentSalaryHike PerformanceRating RelationshipSatisfaction StockOptionLevel TotalWorkingYears TrainingTimesLastYear WorkLifeBalance YearsAtCompany YearsInCurrentRole YearsSinceLastPromotion YearsWithCurrManager born_yyyy generation . EmployeeNumber . 1 41 | 1 | Travel_Rarely | 1102 | Sales | 1 | 2 | Life Sciences | 2 | Female | 94 | 3 | 2 | Sales Executive | 4 | Single | 5993 | 19479 | 8 | Yes | 11 | 3 | 1 | 0 | 8 | 0 | 1 | 6 | 4 | 0 | 5 | 1974 | gen_x | . 2 49 | 0 | Travel_Frequently | 279 | Research &amp; Development | 8 | 1 | Life Sciences | 3 | Male | 61 | 2 | 2 | Research Scientist | 2 | Married | 5130 | 24907 | 1 | No | 23 | 4 | 4 | 1 | 10 | 3 | 3 | 10 | 7 | 1 | 7 | 1966 | gen_x | . 4 37 | 1 | Travel_Rarely | 1373 | Research &amp; Development | 2 | 2 | Other | 4 | Male | 92 | 2 | 1 | Laboratory Technician | 3 | Single | 2090 | 2396 | 6 | Yes | 15 | 3 | 2 | 0 | 7 | 3 | 3 | 0 | 0 | 0 | 0 | 1978 | gen_x | . 5 33 | 0 | Travel_Frequently | 1392 | Research &amp; Development | 3 | 4 | Life Sciences | 4 | Female | 56 | 3 | 1 | Research Scientist | 3 | Married | 2909 | 23159 | 1 | Yes | 11 | 3 | 3 | 0 | 8 | 3 | 3 | 8 | 7 | 3 | 0 | 1982 | gen_y | . 7 27 | 0 | Travel_Rarely | 591 | Research &amp; Development | 2 | 1 | Medical | 1 | Male | 40 | 3 | 1 | Laboratory Technician | 2 | Married | 3468 | 16632 | 9 | No | 12 | 3 | 4 | 1 | 6 | 3 | 3 | 2 | 2 | 2 | 2 | 1988 | gen_y | . Check for Skewness . data[&#39;MonthlyRate&#39;].plot(kind=&#39;kde&#39;) print(&#39;Skewness for Hourly Rate is :&#39; ,data[&#39;MonthlyRate&#39;].skew()) print(&#39;Kurtosis for Hourly Rate is :&#39; ,data[&#39;MonthlyRate&#39;].kurt()) . . Skewness for Hourly Rate is : 0.018577807891132458 Kurtosis for Hourly Rate is : -1.2149560995878737 . data.hist(figsize=(16,12)) plt.tight_layout() . . Log-Transformed skewed features . log_transform = [&#39;DailyRate&#39;, &#39;Age&#39;, &#39;HourlyRate&#39;, &#39;MonthlyIncome&#39;, &#39;PercentSalaryHike&#39;, &#39;DistanceFromHome&#39;, &#39;MonthlyRate&#39;,&#39;born_yyyy&#39;] data[log_transform] = np.log(data[log_transform]) data.describe(include=&#39;all&#39;) . . Age Attrition BusinessTravel DailyRate Department DistanceFromHome Education EducationField EnvironmentSatisfaction Gender HourlyRate JobInvolvement JobLevel JobRole JobSatisfaction MaritalStatus MonthlyIncome MonthlyRate NumCompaniesWorked OverTime PercentSalaryHike PerformanceRating RelationshipSatisfaction StockOptionLevel TotalWorkingYears TrainingTimesLastYear WorkLifeBalance YearsAtCompany YearsInCurrentRole YearsSinceLastPromotion YearsWithCurrManager born_yyyy generation . count 1470.000000 | 1470.000000 | 1470 | 1470.000000 | 1470 | 1470.000000 | 1470.000000 | 1470 | 1470.000000 | 1470 | 1470.000000 | 1470.000000 | 1470.000000 | 1470 | 1470.000000 | 1470 | 1470.000000 | 1470.000000 | 1470.000000 | 1470 | 1470.000000 | 1470.000000 | 1470.000000 | 1470.000000 | 1470.000000 | 1470.000000 | 1470.000000 | 1470.000000 | 1470.000000 | 1470.000000 | 1470.000000 | 1470.000000 | 1470 | . unique NaN | NaN | 3 | NaN | 3 | NaN | NaN | 6 | NaN | 2 | NaN | NaN | NaN | 9 | NaN | 3 | NaN | NaN | NaN | 2 | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | 4 | . top NaN | NaN | Travel_Rarely | NaN | Research &amp; Development | NaN | NaN | Life Sciences | NaN | Male | NaN | NaN | NaN | Sales Executive | NaN | Married | NaN | NaN | NaN | No | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | gen_y | . freq NaN | NaN | 1043 | NaN | 961 | NaN | NaN | 606 | NaN | 882 | NaN | NaN | NaN | 326 | NaN | 673 | NaN | NaN | NaN | 1054 | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | 701 | . mean 3.578034 | 0.161224 | NaN | 6.511255 | NaN | 1.743130 | 2.912925 | NaN | 2.721769 | NaN | 4.135241 | 2.729932 | 2.063946 | NaN | 2.728571 | NaN | 8.552515 | 9.402331 | 2.693197 | NaN | 2.695025 | 3.153741 | 2.712245 | 0.793878 | 11.279592 | 2.799320 | 2.761224 | 7.008163 | 4.229252 | 2.187755 | 4.123129 | 7.589869 | NaN | . std 0.250205 | 0.367863 | NaN | 0.660616 | NaN | 1.060198 | 1.024165 | NaN | 1.093082 | NaN | 0.334764 | 0.711561 | 1.106940 | NaN | 1.102846 | NaN | 0.664450 | 0.633477 | 2.498009 | NaN | 0.228224 | 0.360824 | 1.081209 | 0.852077 | 7.780782 | 1.289271 | 0.706476 | 6.126525 | 3.623137 | 3.222430 | 3.568136 | 0.004623 | NaN | . min 2.890372 | 0.000000 | NaN | 4.624973 | NaN | 0.000000 | 1.000000 | NaN | 1.000000 | NaN | 3.401197 | 1.000000 | 1.000000 | NaN | 1.000000 | NaN | 6.916715 | 7.646831 | 0.000000 | NaN | 2.397895 | 3.000000 | 1.000000 | 0.000000 | 0.000000 | 0.000000 | 1.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 7.578145 | NaN | . 25% 3.401197 | 0.000000 | NaN | 6.142037 | NaN | 0.693147 | 2.000000 | NaN | 2.000000 | NaN | 3.871201 | 2.000000 | 1.000000 | NaN | 2.000000 | NaN | 7.976252 | 8.993055 | 1.000000 | NaN | 2.484907 | 3.000000 | 2.000000 | 0.000000 | 6.000000 | 2.000000 | 2.000000 | 3.000000 | 2.000000 | 0.000000 | 2.000000 | 7.586804 | NaN | . 50% 3.583519 | 0.000000 | NaN | 6.687109 | NaN | 1.945910 | 3.000000 | NaN | 3.000000 | NaN | 4.189655 | 3.000000 | 2.000000 | NaN | 3.000000 | NaN | 8.500858 | 9.563494 | 2.000000 | NaN | 2.639057 | 3.000000 | 3.000000 | 1.000000 | 10.000000 | 3.000000 | 3.000000 | 5.000000 | 3.000000 | 1.000000 | 3.000000 | 7.590347 | NaN | . 75% 3.761200 | 0.000000 | NaN | 7.053586 | NaN | 2.639057 | 4.000000 | NaN | 4.000000 | NaN | 4.427823 | 3.000000 | 3.000000 | NaN | 4.000000 | NaN | 9.033484 | 9.926300 | 4.000000 | NaN | 2.890372 | 3.000000 | 4.000000 | 1.000000 | 15.000000 | 3.000000 | 3.000000 | 9.000000 | 7.000000 | 3.000000 | 7.000000 | 7.593374 | NaN | . max 4.094345 | 1.000000 | NaN | 7.312553 | NaN | 3.367296 | 5.000000 | NaN | 4.000000 | NaN | 4.605170 | 4.000000 | 5.000000 | NaN | 4.000000 | NaN | 9.903438 | 10.203555 | 9.000000 | NaN | 3.218876 | 4.000000 | 4.000000 | 3.000000 | 40.000000 | 6.000000 | 4.000000 | 40.000000 | 18.000000 | 15.000000 | 17.000000 | 7.599401 | NaN | . Encoding Categorical Variables as per ordinal and nomial meaning . List all categorical features . data.select_dtypes(include=&#39;object&#39;).columns . . Index([&#39;BusinessTravel&#39;, &#39;Department&#39;, &#39;EducationField&#39;, &#39;Gender&#39;, &#39;JobRole&#39;, &#39;MaritalStatus&#39;, &#39;OverTime&#39;, &#39;generation&#39;], dtype=&#39;object&#39;) . Encode the ordinal_categorical features - Only OverTime in this dataset . ordinal_categorical = [&#39;OverTime&#39;] feature_map = gen_features(columns= ordinal_categorical, classes=[LabelEncoder]) mapping = DataFrameMapper(feature_map) data[ordinal_categorical] = mapping.fit_transform(data) print(data.shape) data.head(3) . . (1470, 33) . Age Attrition BusinessTravel DailyRate Department DistanceFromHome Education EducationField EnvironmentSatisfaction Gender HourlyRate JobInvolvement JobLevel JobRole JobSatisfaction MaritalStatus MonthlyIncome MonthlyRate NumCompaniesWorked OverTime PercentSalaryHike PerformanceRating RelationshipSatisfaction StockOptionLevel TotalWorkingYears TrainingTimesLastYear WorkLifeBalance YearsAtCompany YearsInCurrentRole YearsSinceLastPromotion YearsWithCurrManager born_yyyy generation . EmployeeNumber . 1 3.713572 | 1 | Travel_Rarely | 7.004882 | Sales | 0.000000 | 2 | Life Sciences | 2 | Female | 4.543295 | 3 | 2 | Sales Executive | 4 | Single | 8.698347 | 9.877092 | 8 | 1 | 2.397895 | 3 | 1 | 0 | 8 | 0 | 1 | 6 | 4 | 0 | 5 | 7.587817 | gen_x | . 2 3.891820 | 0 | Travel_Frequently | 5.631212 | Research &amp; Development | 2.079442 | 1 | Life Sciences | 3 | Male | 4.110874 | 2 | 2 | Research Scientist | 2 | Married | 8.542861 | 10.122904 | 1 | 0 | 3.135494 | 4 | 4 | 1 | 10 | 3 | 3 | 10 | 7 | 1 | 7 | 7.583756 | gen_x | . 4 3.610918 | 1 | Travel_Rarely | 7.224753 | Research &amp; Development | 0.693147 | 2 | Other | 4 | Male | 4.521789 | 2 | 1 | Laboratory Technician | 3 | Single | 7.644919 | 7.781556 | 6 | 1 | 2.708050 | 3 | 2 | 0 | 7 | 3 | 3 | 0 | 0 | 0 | 0 | 7.589842 | gen_x | . Encode the nominal_categorical features . nominal_categorical = [&#39;BusinessTravel&#39;, &#39;Department&#39;, &#39;EducationField&#39;, &#39;Gender&#39;, &#39;JobRole&#39;, &#39;MaritalStatus&#39;, &#39;generation&#39;] d_dummies = data.copy() for col in nominal_categorical: freqs = d_dummies[col].value_counts() k = freqs.index[freqs&gt;5][:-1] # does the work of One Hot Encoding for cat in k: name = col+&#39;_&#39;+cat d_dummies[name] = (d_dummies[col] == cat).astype(int) del d_dummies[col] print(col) print(d_dummies.shape) d_dummies.head(2) . . BusinessTravel Department EducationField Gender JobRole MaritalStatus generation (1470, 49) . Age Attrition DailyRate DistanceFromHome Education EnvironmentSatisfaction HourlyRate JobInvolvement JobLevel JobSatisfaction MonthlyIncome MonthlyRate NumCompaniesWorked OverTime PercentSalaryHike PerformanceRating RelationshipSatisfaction StockOptionLevel TotalWorkingYears TrainingTimesLastYear WorkLifeBalance YearsAtCompany YearsInCurrentRole YearsSinceLastPromotion YearsWithCurrManager born_yyyy BusinessTravel_Travel_Rarely BusinessTravel_Travel_Frequently Department_Research &amp; Development Department_Sales EducationField_Life Sciences EducationField_Medical EducationField_Marketing EducationField_Technical Degree EducationField_Other Gender_Male JobRole_Sales Executive JobRole_Research Scientist JobRole_Laboratory Technician JobRole_Manufacturing Director JobRole_Healthcare Representative JobRole_Manager JobRole_Sales Representative JobRole_Research Director MaritalStatus_Married MaritalStatus_Single generation_gen_y generation_gen_x generation_gen_baby_boomer . EmployeeNumber . 1 3.713572 | 1 | 7.004882 | 0.000000 | 2 | 2 | 4.543295 | 3 | 2 | 4 | 8.698347 | 9.877092 | 8 | 1 | 2.397895 | 3 | 1 | 0 | 8 | 0 | 1 | 6 | 4 | 0 | 5 | 7.587817 | 1 | 0 | 0 | 1 | 1 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 1 | 0 | . 2 3.891820 | 0 | 5.631212 | 2.079442 | 1 | 3 | 4.110874 | 2 | 2 | 2 | 8.542861 | 10.122904 | 1 | 0 | 3.135494 | 4 | 4 | 1 | 10 | 3 | 3 | 10 | 7 | 1 | 7 | 7.583756 | 0 | 1 | 1 | 0 | 1 | 0 | 0 | 0 | 0 | 1 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 1 | 0 | . Classification Models . Model Setup and Evaluation Criteria . Predicting employee attrition is a classic supervised learning problem. For classification modelling and performance evaluation the dataset is split into a 70:30 ratio for training and testing respectively. Dependent variable is Attrition with positive class label as ‘Yes’ indicating employee underwent attrition. We aim to focus on accurately predicting employees that are more likely to churn and avoid missing out on predicting employees ‘at-risk’ of attrition - even if it means over-predicting them. We propose 4 classifiers and discussed in Section 3.2 and analysed results in Section 4. Recall and F1 Score will be used for evaluating model performance for employee attrition problem. These metrics are chosen because Recall interprets ‘What percentage of the employees being attrited does the classifier successfully report?’ Maximizing Recall would imply minimizing under-shooting or False Negatives In our case, Precision interprets ‘Employees that are predicted to leave by classifier, how many employees truly underwent attrition?’ Maximizing Precision would imply Minimize over-shooting that is to take action for employees ‘at-risk’ of attrition. However, since we don’t want to compromise precision too much, we will also take into account F1 Score which is the harmonic mean between precision and recall to strike a balance between the two. . Logistic Regression, Decision Trees and Random Forest . classifiers = {&#39;LR&#39;: LogisticRegression(), &#39;DT&#39;: DecisionTreeClassifier(class_weight=&#39;balanced&#39;), &#39;RFC&#39;: RandomForestClassifier(class_weight=&#39;balanced&#39;)} color = {&#39;LR&#39;: &#39;orange&#39;, &#39;DT&#39;: &#39;green&#39;,&#39;RFC&#39;: &#39;blue&#39;, &#39;rfc_hp_tuned&#39;:&#39;yellow&#39;, &#39;rfc_hp_tuned_balanced&#39;:&#39;brown&#39;} def model_eval(algo, algo_name, X_train , y_train , X_test , y_test): algo.fit(X_train , y_train) y_pred = algo.predict(X_train) y_train_pred = algo.predict(X_train) # Finding the positives and negatives y_train_prob = algo.predict_proba(X_train)[:,1] #we are intersted only in the second column y_test_pred = algo.predict(X_test) y_test_prob = algo.predict_proba(X_test)[:,1] conf_m = confusion_matrix(y_test , y_test_pred, labels=[0,1]) FNR = conf_m[1][0] * 100 / (conf_m[1][0] + conf_m[1][1]) cv_accuracy=np.mean(cross_val_score(algo, X_test, y_test,cv=5,scoring=&#39;accuracy&#39;)*100) cv_roc_auc=cross_val_score(algo, X_test, y_test,cv=5,scoring=&#39;roc_auc&#39;)*100 #overall acc of train model print(&#39;*&#39;*50) print(algo_name) print(&quot;Training Metrics&quot;) print(&#39;Confusion matrix - Train :&#39;, &#39; n&#39;,confusion_matrix(y_train , y_train_pred, labels=[0,1])) print(&#39;Overall Accuracy - Train :&#39;,accuracy_score(y_train , y_train_pred)) print(&#39;AUC - Train:&#39;, roc_auc_score(y_train , y_train_prob)) print(&#39;*&#39;*50) print(&quot;Testing Metrics&quot;) print(&#39;Confusion matrix - Test :&#39;, &#39; n&#39;, conf_m) print(&#39;Overall Accuracy - Test :&#39;,accuracy_score(y_test , y_test_pred)) print(&#39;AUC - Test:&#39;, roc_auc_score(y_test , y_test_prob)) print(&#39;*&#39;*50) print(&#39; n5-fold Cross Validation Scores&#39;) print(f&#39;cv_accuracy: {cv_accuracy} ncv_roc_auc: {np.mean(cv_roc_auc)} n&#39;) print(&#39;Classification Report: n&#39;, classification_report(y_test, y_test_pred)) fpr , tpr , threshold = roc_curve(y_test , y_test_prob) plt.plot(fpr , fpr, &#39;r-&#39;) plt.plot(fpr , tpr , color=color[algo_name], label=algo_name) plt.title(&quot;Receiver Operating Characteristics(ROC) Curve&quot;) plt.xlabel(&#39;False Positive Rate&#39;, fontsize=16) plt.ylabel(&#39;True Positive Rate&#39;, fontsize=16) plt.legend(loc=&#39;best&#39;) return y_test_pred, y_test_prob . . corr_dummies = d_dummies.corr() high_corr_cols = corr_dummies[abs(corr_dummies[&#39;Attrition&#39;]) &gt;= 0.1].index corr_dummies.loc[high_corr_cols].sort_values(by=&#39;Attrition&#39;).style.background_gradient(cmap=&#39;coolwarm&#39;) y = d_dummies[&#39;Attrition&#39;] X = d_dummies[high_corr_cols].drop([&#39;Attrition&#39;,&#39;Age&#39;,&#39;TotalWorkingYears&#39;], axis=1) X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1, stratify=y) print(X.shape, y.shape) print(X_train.shape, X_test.shape, y_train.shape, y_test.shape) . . (1470, 16) (1470,) (1029, 16) (441, 16) (1029,) (441,) . Classification Model Evaluation . print(&#39;Scores for basic models: n&#39;) for key in classifiers: y_test_pred, y_test_prob = model_eval(classifiers[key], key, X_train, y_train, X_test, y_test) . . Scores for basic models: ************************************************** LR Training Metrics Confusion matrix - Train : [[849 14] [119 47]] Overall Accuracy - Train : 0.8707482993197279 AUC - Train: 0.8168339638973043 ************************************************** Testing Metrics Confusion matrix - Test : [[358 12] [ 41 30]] Overall Accuracy - Test : 0.8798185941043084 AUC - Test: 0.826570232204035 ************************************************** 5-fold Cross Validation Scores cv_accuracy: 87.30081716036773 cv_roc_auc: 81.33462033462033 Classification Report: precision recall f1-score support 0 0.90 0.97 0.93 370 1 0.71 0.42 0.53 71 accuracy 0.88 441 macro avg 0.81 0.70 0.73 441 weighted avg 0.87 0.88 0.87 441 ************************************************** DT Training Metrics Confusion matrix - Train : [[863 0] [ 0 166]] Overall Accuracy - Train : 1.0 AUC - Train: 1.0 ************************************************** Testing Metrics Confusion matrix - Test : [[314 56] [ 43 28]] Overall Accuracy - Test : 0.7755102040816326 AUC - Test: 0.6215074229158737 ************************************************** 5-fold Cross Validation Scores cv_accuracy: 80.04596527068438 cv_roc_auc: 61.53796653796653 Classification Report: precision recall f1-score support 0 0.88 0.85 0.86 370 1 0.33 0.39 0.36 71 accuracy 0.78 441 macro avg 0.61 0.62 0.61 441 weighted avg 0.79 0.78 0.78 441 ************************************************** RFC Training Metrics Confusion matrix - Train : [[863 0] [ 0 166]] Overall Accuracy - Train : 1.0 AUC - Train: 1.0 ************************************************** Testing Metrics Confusion matrix - Test : [[361 9] [ 48 23]] Overall Accuracy - Test : 0.8707482993197279 AUC - Test: 0.8078226113437382 ************************************************** 5-fold Cross Validation Scores cv_accuracy: 87.75280898876404 cv_roc_auc: 76.72779922779924 Classification Report: precision recall f1-score support 0 0.88 0.98 0.93 370 1 0.72 0.32 0.45 71 accuracy 0.87 441 macro avg 0.80 0.65 0.69 441 weighted avg 0.86 0.87 0.85 441 . Data Augmentation . SMOTE: Synthetic Minority Oversampling Technique . SMOTE should be applied on the training set. Then, the model should be &quot;evaluated on the stratified but non-transformed test set&quot; | . y_aug = copy.deepcopy(y.values) x_aug = copy.deepcopy(X.values) def aug_pipeline(clf, clf_name, X_train, y_train, X_test, y_test): smt = SMOTE(random_state=0) X_train_aug, y_train_aug = smt.fit_resample(X_train, y_train) print(X.shape, y.shape) print(X_train_aug.shape, X_test.shape, y_train_aug.shape, y_test.shape) print(np.unique(y_train_aug, return_counts=True)) return model_eval(clf, clf_name, X_train_aug, y_train_aug, X_test, y_test) print(&#39;Scores for basic models, trained on augmented balanced data: n&#39;) for key in classifiers: aug_pipeline(classifiers[key], key, X_train, y_train, X_test, y_test) . . Scores for basic models, trained on augmented balanced data: (1470, 16) (1470,) (1726, 16) (441, 16) (1726,) (441,) (array([0, 1], dtype=int64), array([863, 863], dtype=int64)) ************************************************** LR Training Metrics Confusion matrix - Train : [[721 142] [137 726]] Overall Accuracy - Train : 0.8383545770567786 AUC - Train: 0.9083595047591939 ************************************************** Testing Metrics Confusion matrix - Test : [[294 76] [ 27 44]] Overall Accuracy - Test : 0.7664399092970522 AUC - Test: 0.7647887323943662 ************************************************** 5-fold Cross Validation Scores cv_accuracy: 87.30081716036773 cv_roc_auc: 81.33462033462033 Classification Report: precision recall f1-score support 0 0.92 0.79 0.85 370 1 0.37 0.62 0.46 71 accuracy 0.77 441 macro avg 0.64 0.71 0.66 441 weighted avg 0.83 0.77 0.79 441 (1470, 16) (1470,) (1726, 16) (441, 16) (1726,) (441,) (array([0, 1], dtype=int64), array([863, 863], dtype=int64)) ************************************************** DT Training Metrics Confusion matrix - Train : [[863 0] [ 0 863]] Overall Accuracy - Train : 1.0 AUC - Train: 1.0 ************************************************** Testing Metrics Confusion matrix - Test : [[284 86] [ 36 35]] Overall Accuracy - Test : 0.7233560090702947 AUC - Test: 0.6302626570232204 ************************************************** 5-fold Cross Validation Scores cv_accuracy: 79.14708886618999 cv_roc_auc: 65.33204633204633 Classification Report: precision recall f1-score support 0 0.89 0.77 0.82 370 1 0.29 0.49 0.36 71 accuracy 0.72 441 macro avg 0.59 0.63 0.59 441 weighted avg 0.79 0.72 0.75 441 (1470, 16) (1470,) (1726, 16) (441, 16) (1726,) (441,) (array([0, 1], dtype=int64), array([863, 863], dtype=int64)) ************************************************** RFC Training Metrics Confusion matrix - Train : [[862 1] [ 0 863]] Overall Accuracy - Train : 0.9994206257242179 AUC - Train: 1.0 ************************************************** Testing Metrics Confusion matrix - Test : [[334 36] [ 40 31]] Overall Accuracy - Test : 0.8276643990929705 AUC - Test: 0.749371907118386 ************************************************** 5-fold Cross Validation Scores cv_accuracy: 87.75025536261492 cv_roc_auc: 78.44723294723295 Classification Report: precision recall f1-score support 0 0.89 0.90 0.90 370 1 0.46 0.44 0.45 71 accuracy 0.83 441 macro avg 0.68 0.67 0.67 441 weighted avg 0.82 0.83 0.83 441 . Logistic Regression Model Equations and Feature importance . # form F(x) equation for printing in report lr = LogisticRegression(fit_intercept=True) y_test_pred, y_test_prob = model_eval(lr, &#39;LR&#39;, X_train , y_train , X_test , y_test) lr_eqn = f&quot;{round(lr.intercept_[0], 4)} + &quot; for i in range(len(X_train.columns)): lr_eqn = lr_eqn + f&quot;({round(lr.coef_[0][i],3)}*{X_train.columns[i]}) + &quot; . . ************************************************** LR Training Metrics Confusion matrix - Train : [[849 14] [119 47]] Overall Accuracy - Train : 0.8707482993197279 AUC - Train: 0.8168339638973043 ************************************************** Testing Metrics Confusion matrix - Test : [[358 12] [ 41 30]] Overall Accuracy - Test : 0.8798185941043084 AUC - Test: 0.826570232204035 ************************************************** 5-fold Cross Validation Scores cv_accuracy: 87.30081716036773 cv_roc_auc: 81.33462033462033 Classification Report: precision recall f1-score support 0 0.90 0.97 0.93 370 1 0.71 0.42 0.53 71 accuracy 0.88 441 macro avg 0.81 0.70 0.73 441 weighted avg 0.87 0.88 0.87 441 . print(lr_eqn) . . 0.1535 + (-0.403*EnvironmentSatisfaction) + (-0.531*JobInvolvement) + (-0.145*JobLevel) + (-0.415*JobSatisfaction) + (-0.535*MonthlyIncome) + (1.433*OverTime) + (-0.197*StockOptionLevel) + (0.083*YearsAtCompany) + (-0.111*YearsInCurrentRole) + (-0.104*YearsWithCurrManager) + (0.83*born_yyyy) + (0.821*BusinessTravel_Travel_Frequently) + (0.609*JobRole_Sales Representative) + (0.732*MaritalStatus_Single) + (-0.206*generation_gen_y) + (-0.637*generation_gen_x) + . f_x_test = lr.intercept_[0] + sum([lr.coef_[0][i]*X_test.iloc[:, i] for i in range(len(X_test.columns))]) prob = np.exp(f_x_test) / (1 + np.exp(f_x_test)) . . results = pd.DataFrame({&#39;Log_odds_f(x)&#39;: f_x_test.values, &#39;Probability_p+(x)&#39;:prob.values, &#39;Predicted Attrition y_pred&#39;: y_test_pred, &#39;True Attrition y_test&#39;: y_test.values}, index = f_x_test.index) results.sort_values(by=&#39;True Attrition y_test&#39;, ascending=False).head() . . Log_odds_f(x) Probability_p+(x) Predicted Attrition y_pred True Attrition y_test . EmployeeNumber . 816 0.990499 | 0.729186 | 1 | 1 | . 648 1.057191 | 0.742153 | 1 | 1 | . 1004 0.280909 | 0.569769 | 1 | 1 | . 1458 1.645732 | 0.838313 | 1 | 1 | . 137 0.775118 | 0.684627 | 1 | 1 | . plt.figure(figsize=(14,6)) plt.title(&#39;Coefficient Estimation in Employee Attrition Problem using Logistic Regression&#39;, fontsize=18) p = sns.lineplot(data=results, x = &#39;Probability_p+(x)&#39;, y=&#39;Log_odds_f(x)&#39;, marker=&#39;.&#39;, markerfacecolor=&#39;black&#39;, markersize=&#39;10&#39;, label=&#39;Logit function&#39;, linewidth=6) p.set_xlabel(&#39;Log-odds/Logit Function f(x)&#39;, fontsize = 16) p.set_ylabel(&#39;Probability of Attrition p+(x)&#39;, fontsize = 16) . . Text(0, 0.5, &#39;Probability of Attrition p+(x)&#39;) . Feature Importance for Logistic Regression . # get importance: in linear models the importance is given by coefficients importances = lr.coef_[0] names = X_train.columns importances, names = zip(*sorted(zip(importances, names))) # Lets plot this plt.figure(figsize=(10,6)) plt.barh(range(len(names)), importances, align = &#39;center&#39;) plt.yticks(range(len(names)), names) plt.xlabel(&#39;Coefficients as Importance indicators of features&#39;, fontsize = 16) plt.ylabel(&#39;Features&#39;,fontsize = 16) plt.title(&#39;Feature Importance for Logistic Regression&#39;,fontsize = 18) plt.show() ### inference: # We can observe that features that are inversely proportional to attrition such as high job satisfaction, Environment Satisfaction, . . Random Forest HyperParameter-Tuning and Feature importance . from scipy.stats import randint as sp_randint from sklearn.ensemble import RandomForestClassifier from sklearn.model_selection import RandomizedSearchCV rfc = RandomForestClassifier(random_state=3) params = { &#39;n_estimators&#39; : sp_randint(15 , 200) , &#39;max_depth&#39; : sp_randint(2,15) , &#39;min_samples_split&#39; : sp_randint(2,10) , &#39;min_samples_leaf&#39; : sp_randint(1,10) , &#39;criterion&#39; : [&#39;gini&#39; , &#39;entropy&#39;] } rsearch_rfc = RandomizedSearchCV(rfc , param_distributions= params , n_iter= 50 , cv = 5 , scoring=&#39;recall&#39; , random_state= 3 , return_train_score=True , n_jobs=-1) rsearch_rfc.fit(X,y) . . RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(random_state=3), n_iter=50, n_jobs=-1, param_distributions={&#39;criterion&#39;: [&#39;gini&#39;, &#39;entropy&#39;], &#39;max_depth&#39;: &lt;scipy.stats._distn_infrastructure.rv_frozen object at 0x000001E915F64D08&gt;, &#39;min_samples_leaf&#39;: &lt;scipy.stats._distn_infrastructure.rv_frozen object at 0x000001E914A7EF08&gt;, &#39;min_samples_split&#39;: &lt;scipy.stats._distn_infrastructure.rv_frozen object at 0x000001E914A42748&gt;, &#39;n_estimators&#39;: &lt;scipy.stats._distn_infrastructure.rv_frozen object at 0x000001E915F60F08&gt;}, random_state=3, return_train_score=True, scoring=&#39;recall&#39;) . rsearch_rfc.best_params_ . . {&#39;criterion&#39;: &#39;gini&#39;, &#39;max_depth&#39;: 12, &#39;min_samples_leaf&#39;: 1, &#39;min_samples_split&#39;: 2, &#39;n_estimators&#39;: 91} . rfc= RandomForestClassifier(**rsearch_rfc.best_params_,random_state=3) y_test_pred, y_test_prob = model_eval(rfc , &#39;rfc_hp_tuned&#39;, X_train , y_train , X_test , y_test) y_test_pred, y_test_prob = aug_pipeline(rfc , &#39;rfc_hp_tuned_balanced&#39;, X_train, y_train, X_test, y_test) . . ************************************************** rfc_hp_tuned Training Metrics Confusion matrix - Train : [[863 0] [ 7 159]] Overall Accuracy - Train : 0.9931972789115646 AUC - Train: 1.0 ************************************************** Testing Metrics Confusion matrix - Test : [[362 8] [ 45 26]] Overall Accuracy - Test : 0.8798185941043084 AUC - Test: 0.8133993148077654 ************************************************** 5-fold Cross Validation Scores cv_accuracy: 87.07099080694586 cv_roc_auc: 78.37773487773487 Classification Report: precision recall f1-score support 0 0.89 0.98 0.93 370 1 0.76 0.37 0.50 71 accuracy 0.88 441 macro avg 0.83 0.67 0.71 441 weighted avg 0.87 0.88 0.86 441 (1470, 16) (1470,) (1726, 16) (441, 16) (1726,) (441,) (array([0, 1], dtype=int64), array([863, 863], dtype=int64)) ************************************************** rfc_hp_tuned_balanced Training Metrics Confusion matrix - Train : [[860 3] [ 0 863]] Overall Accuracy - Train : 0.9982618771726536 AUC - Train: 0.9999597190538274 ************************************************** Testing Metrics Confusion matrix - Test : [[325 45] [ 39 32]] Overall Accuracy - Test : 0.8095238095238095 AUC - Test: 0.7544156832889227 ************************************************** 5-fold Cross Validation Scores cv_accuracy: 87.07099080694586 cv_roc_auc: 78.37773487773487 Classification Report: precision recall f1-score support 0 0.89 0.88 0.89 370 1 0.42 0.45 0.43 71 accuracy 0.81 441 macro avg 0.65 0.66 0.66 441 weighted avg 0.82 0.81 0.81 441 . importances = rfc.feature_importances_ names = X_train.columns importances, names = zip(*sorted(zip(importances, names))) # Lets plot this plt.figure(figsize=(12,8)) plt.barh(range(len(names)), importances, align = &#39;center&#39;) plt.yticks(range(len(names)), names, fontsize = 14) plt.xlabel(&#39;Importance of features&#39;, fontsize = 16) plt.ylabel(&#39;Features&#39;, fontsize = 16) plt.title(&#39;Feature Importance for Random Forest&#39;, fontsize = 18) plt.show() . . PCR = PCA + Regression/Classification . Principle Component Regression (PCR) is an algorithm for reducing the multi-collinearity of a dataset. The problem we face in multi-variate linear regression (linear regression with a large number of features) is that although it may appear that we do fit the model well, there is normally a high-variance problem on the test set. The key idea of how PCR aims to do this, is to use PCA on the dataset before regression/classification. In PCR instead of regressing the dependent variable on the independent variables directly, the principal components of the independent variables are used. . Bias-Variance Tradeoff In order to prevent this degree of overfitting, PCR aims to add a slight bias, such that we are now aiming to fit the model with a slightly less training accuracy, but aim to reduce the variance to a large extent. PCR aims to achieve something very similar to what Ridge Regression tries to do. Both of these methods try to reduce overfitting, but differ in their approach . NOTE: PCR is NOT a feature selection method, as a feature selection method would involve selecting a few features as it is, out of all of them. Instead, we are combining features to create new PCs, which are different from the original features. PCR is particularly useful on datasets facing the problem of multi-collinearity On datasets with highly correlated features, or even collinear features, PCR is quite useful PCR reduces the problem of overfitting . Implementation: . To determine the lower M-dimensional space, firstly the high-dimension dataset with all features and data points is normalized to have a mean 0 and standard deviation 1 and transformed to obtain PCs. Normalized PCs ensure that no predictor variable is overly influential in the model if it happens to be measured in different units. Resultant PCs are fitted and the transformed dataset(X_reduced) is fed to a 10-fold Cross Validation logistic regression model over a loop which adds dimensions one-by-one and reports the accuracy of this PCR formulation. The accuracy and ‘explained_varianceratio’ for all dimensions helps us in selecting the optimum number of components on which we train our splitted training dataset and predict test accuracy of 89%. We extend the PCA model by regressing a logistic regression aimed at binary classification to predict potential attrition in the organisation. PCA and logistic regression is applied on all the PCs. . # Defining y and X for basic PCA() Estimation y = d_dummies.Attrition # Drop the column with the independent variable Attrtion, non-impacting variable EmployeeNumber and columns for which we have created dummy variables X = d_dummies.drop([&#39;Attrition&#39;], axis=1) display( X.shape, X.head(2) ) . . (1470, 48) . Age DailyRate DistanceFromHome Education EnvironmentSatisfaction HourlyRate JobInvolvement JobLevel JobSatisfaction MonthlyIncome MonthlyRate NumCompaniesWorked OverTime PercentSalaryHike PerformanceRating RelationshipSatisfaction StockOptionLevel TotalWorkingYears TrainingTimesLastYear WorkLifeBalance YearsAtCompany YearsInCurrentRole YearsSinceLastPromotion YearsWithCurrManager born_yyyy BusinessTravel_Travel_Rarely BusinessTravel_Travel_Frequently Department_Research &amp; Development Department_Sales EducationField_Life Sciences EducationField_Medical EducationField_Marketing EducationField_Technical Degree EducationField_Other Gender_Male JobRole_Sales Executive JobRole_Research Scientist JobRole_Laboratory Technician JobRole_Manufacturing Director JobRole_Healthcare Representative JobRole_Manager JobRole_Sales Representative JobRole_Research Director MaritalStatus_Married MaritalStatus_Single generation_gen_y generation_gen_x generation_gen_baby_boomer . EmployeeNumber . 1 3.713572 | 7.004882 | 0.000000 | 2 | 2 | 4.543295 | 3 | 2 | 4 | 8.698347 | 9.877092 | 8 | 1 | 2.397895 | 3 | 1 | 0 | 8 | 0 | 1 | 6 | 4 | 0 | 5 | 7.587817 | 1 | 0 | 0 | 1 | 1 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 1 | 0 | . 2 3.891820 | 5.631212 | 2.079442 | 1 | 3 | 4.110874 | 2 | 2 | 2 | 8.542861 | 10.122904 | 1 | 0 | 3.135494 | 4 | 4 | 1 | 10 | 3 | 3 | 10 | 7 | 1 | 7 | 7.583756 | 0 | 1 | 1 | 0 | 1 | 0 | 0 | 0 | 0 | 1 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 1 | 0 | . Transform Fit PCA + Logistic Regression on entire dataset . Defining PCA object ~ What&#39;s scale for? . pca.fit_transform(scale(X)): This tells Python that each of the predictor variables should be scaled to have a mean of 0 and a standard deviation of 1. This ensures that no predictor variable is overly influential in the model if it happens to be measured in different units | . # Check the number of PC&#39;s to use during training by classifying the PC&#39;s on entire dataset pca = PCA() X_reduced = pca.fit_transform(scale(X)) # 10-fold CV, with shuffle n = len(X_reduced) kf_10 = KFold( n_splits=10, shuffle=True, random_state=1) logR = LogisticRegression(random_state=0) cv_acc_results = [] # Calculate Accuracy with only the intercept (no principal components in Log regression) score = cross_val_score(logR, np.ones((n,1)), y, cv = kf_10, scoring=&#39;accuracy&#39;) cv_acc_results.append(round(score.mean()*100, 2)) print(cv_acc_results) # Calculate Accuracy using CV for the all principle components, adding one component at the time. for i in np.arange(1, len(X.columns)): score = cross_val_score(logR, X_reduced[:,:i], y, cv=kf_10, scoring=&#39;accuracy&#39;).mean() cv_acc_results.append(round(score.mean()*100, 2)) print(cv_acc_results[30:38]) # check when results start to exceed 88% what is the number of PCs or n_components # We will use this n_components in training and test models . . [83.88] [88.37, 87.82, 88.03, 87.89, 88.03, 87.82, 88.03, 88.03] . # Plot results plt.figure(figsize=(8,4)) plt.plot(cv_acc_results, &#39;-v&#39;) plt.xlabel(&#39;Number of PCs&#39;, fontsize=16) plt.ylabel(&#39;Accuracy&#39;, fontsize=16) plt.title(&#39;Cross Validated Accuracy vs Number of PCs&#39;, fontsize=18) plt.xlim(xmin=-1); # pd.DataFrame(pca.components_.T) . . var_exp = np.round(pca.explained_variance_ratio_, decimals=4)*100 cum_var_exp = np.cumsum(var_exp) plt.figure(figsize=(7,4)) plt.bar(range(X.shape[1]),var_exp,alpha=0.5,align=&#39;center&#39;,label=&#39;Individual explained variance&#39;) plt.step(range(X.shape[1]),cum_var_exp,where=&#39;mid&#39;,label=&#39;cummulative explained variance&#39;) plt.ylabel(&quot;Explained variance ratio&quot;, fontsize=16) plt.xlabel(&quot;Number of PCs&quot;, fontsize=16) plt.title(&#39;Attrition Explained by k PCs&#39;, fontsize=18) plt.legend(loc=&#39;best&#39;) plt.tight_layout() plt.show() # notice explanatory ratio from 90-95% around 32-35 : we can choose any dimension between this . . Split Dataset . # Split into training and test sets X_train, X_test , y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1, stratify=y) print(X_train.shape) print(X_test.shape) print(y_train.shape) print(y_test.shape) print(X.shape) print(y.shape) . . (1029, 48) (441, 48) (1029,) (441,) (1470, 48) (1470,) . Transform fit PCR on Training Dataset and Evlauate Performance . for i in range(30, 38): n_components = i pca2 = PCA(n_components=n_components) X_reduced_train = pca2.fit_transform(scale(X_train)) X_reduced_test = pca2.transform(scale(X_test)) logR = LogisticRegression() logR.fit(X_reduced_train, y_train) # PRediction with training data y_train_pred = logR.predict(X_reduced_train) y_train_prob = logR.predict_proba(X_reduced_train) # Prediction with test data y_pred = logR.predict(X_reduced_test) y_test_prob = logR.predict_proba(X_reduced_test)[:,1] y_test_pred = y_pred algo = logR conf_m = confusion_matrix(y_test , y_test_pred) #overall acc of train model print(&#39;*&#39;*50) print(&quot;Training Metrics&quot;) print(&#39;Confusion matrix - Train :&#39;, &#39; n&#39;,confusion_matrix(y_train , y_train_pred, labels=[0,1])) print(&#39;Overall Accuracy - Train :&#39;,accuracy_score(y_train , y_train_pred)) print(&#39;*&#39;*50) print(&quot;Testing Metrics&quot;) print(&#39;Confusion matrix - Test :&#39;, &#39; n&#39;, conf_m) print(&#39;Overall Accuracy - Test :&#39;,accuracy_score(y_test , y_test_pred)) print(&#39;AUC - Test:&#39;, roc_auc_score(y_test , y_test_prob)) print(&#39;*&#39;*50) print(&#39;Classification Report: n&#39;, classification_report(y_test, y_test_pred)) fpr , tpr , threshold = roc_curve(y_test , y_test_prob) plt.plot(fpr , fpr, &#39;r-&#39;) plt.plot(fpr , tpr , label=f&#39;{i} PCs&#39;) plt.title(&quot;Receiver Operating Characteristics(ROC) Curve&quot;) plt.xlabel(&#39;False Positive Rate&#39;, fontsize=16) plt.ylabel(&#39;True Positive Rate&#39;, fontsize=16) plt.legend(loc=&#39;best&#39;) . . ************************************************** Training Metrics Confusion matrix - Train : [[848 15] [102 64]] Overall Accuracy - Train : 0.8862973760932945 ************************************************** Testing Metrics Confusion matrix - Test : [[365 5] [ 49 22]] Overall Accuracy - Test : 0.8775510204081632 AUC - Test: 0.795317853064332 ************************************************** Classification Report: precision recall f1-score support 0 0.88 0.99 0.93 370 1 0.81 0.31 0.45 71 accuracy 0.88 441 macro avg 0.85 0.65 0.69 441 weighted avg 0.87 0.88 0.85 441 ************************************************** Training Metrics Confusion matrix - Train : [[844 19] [ 94 72]] Overall Accuracy - Train : 0.8901846452866861 ************************************************** Testing Metrics Confusion matrix - Test : [[364 6] [ 45 26]] Overall Accuracy - Test : 0.8843537414965986 AUC - Test: 0.828968405024743 ************************************************** Classification Report: precision recall f1-score support 0 0.89 0.98 0.93 370 1 0.81 0.37 0.50 71 accuracy 0.88 441 macro avg 0.85 0.67 0.72 441 weighted avg 0.88 0.88 0.87 441 ************************************************** Training Metrics Confusion matrix - Train : [[843 20] [ 92 74]] Overall Accuracy - Train : 0.891156462585034 ************************************************** Testing Metrics Confusion matrix - Test : [[365 5] [ 45 26]] Overall Accuracy - Test : 0.8866213151927438 AUC - Test: 0.8326608298439284 ************************************************** Classification Report: precision recall f1-score support 0 0.89 0.99 0.94 370 1 0.84 0.37 0.51 71 accuracy 0.89 441 macro avg 0.86 0.68 0.72 441 weighted avg 0.88 0.89 0.87 441 ************************************************** Training Metrics Confusion matrix - Train : [[843 20] [ 88 78]] Overall Accuracy - Train : 0.8950437317784257 ************************************************** Testing Metrics Confusion matrix - Test : [[364 6] [ 45 26]] Overall Accuracy - Test : 0.8843537414965986 AUC - Test: 0.8427864484202512 ************************************************** Classification Report: precision recall f1-score support 0 0.89 0.98 0.93 370 1 0.81 0.37 0.50 71 accuracy 0.88 441 macro avg 0.85 0.67 0.72 441 weighted avg 0.88 0.88 0.87 441 ************************************************** Training Metrics Confusion matrix - Train : [[842 21] [ 87 79]] Overall Accuracy - Train : 0.8950437317784257 ************************************************** Testing Metrics Confusion matrix - Test : [[364 6] [ 43 28]] Overall Accuracy - Test : 0.8888888888888888 AUC - Test: 0.8421773886562619 ************************************************** Classification Report: precision recall f1-score support 0 0.89 0.98 0.94 370 1 0.82 0.39 0.53 71 accuracy 0.89 441 macro avg 0.86 0.69 0.74 441 weighted avg 0.88 0.89 0.87 441 ************************************************** Training Metrics Confusion matrix - Train : [[843 20] [ 88 78]] Overall Accuracy - Train : 0.8950437317784257 ************************************************** Testing Metrics Confusion matrix - Test : [[363 7] [ 42 29]] Overall Accuracy - Test : 0.8888888888888888 AUC - Test: 0.8402740768937952 ************************************************** Classification Report: precision recall f1-score support 0 0.90 0.98 0.94 370 1 0.81 0.41 0.54 71 accuracy 0.89 441 macro avg 0.85 0.69 0.74 441 weighted avg 0.88 0.89 0.87 441 ************************************************** Training Metrics Confusion matrix - Train : [[842 21] [ 88 78]] Overall Accuracy - Train : 0.8940719144800777 ************************************************** Testing Metrics Confusion matrix - Test : [[365 5] [ 41 30]] Overall Accuracy - Test : 0.8956916099773242 AUC - Test: 0.8455272173582032 ************************************************** Classification Report: precision recall f1-score support 0 0.90 0.99 0.94 370 1 0.86 0.42 0.57 71 accuracy 0.90 441 macro avg 0.88 0.70 0.75 441 weighted avg 0.89 0.90 0.88 441 ************************************************** Training Metrics Confusion matrix - Train : [[842 21] [ 89 77]] Overall Accuracy - Train : 0.8931000971817298 ************************************************** Testing Metrics Confusion matrix - Test : [[363 7] [ 42 29]] Overall Accuracy - Test : 0.8888888888888888 AUC - Test: 0.8430529120669965 ************************************************** Classification Report: precision recall f1-score support 0 0.90 0.98 0.94 370 1 0.81 0.41 0.54 71 accuracy 0.89 441 macro avg 0.85 0.69 0.74 441 weighted avg 0.88 0.89 0.87 441 . Performance Evaluation for PCR . One of the Advantages of PCR is that it alleviates multicollinearity in our 48 dimension dataset by reducing it to 33 dimensions because the 33 PCs well approximate 95% essence of the high dimensional dataset which can be monitored using the ‘explained_varianceratio’ parameter. PCR also prevents overfitting on training datasets by introducing a slight bias while training. This facilitates a bias-variance trade-off by reducing variance on the test dataset to a large extent but decreases the training accuracy which is a fair trade-off to avoid overfitting. Major disadvantage of PCR is that PCR produces models that are difficult to interpret since PCs cannot be interpreted to conclude for the feature importance. Hence, we look forward to exploring more interpretable models so as to accurately understand the importance of features in attrition. .",
            "url": "https://contactmansi.github.io/workoutdata/hr-analytics/churn%20analysis/classification/recall/ibm-dataset/kaggle/2022/01/15/Employee-Churn-Prediction-HR-Analytics.html",
            "relUrl": "/hr-analytics/churn%20analysis/classification/recall/ibm-dataset/kaggle/2022/01/15/Employee-Churn-Prediction-HR-Analytics.html",
            "date": " • Jan 15, 2022"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "Mansi is currently working as Senior Data Engineer at Singapore Airlines along with pursuing Masters in Business Analytics(part-time) at NUS, Singapore. She has been leveraging Data Science, Business Knowledge, Machine Learning and Software Engineering to deliver innovative solutions for complex data-oriented problems. . TOP SKILLS: . Data Pipelining, Data Warehouse Management, Pyspark, Airflow, AWS Services | Modeling: Predictive and Statistical Modelling, Supervised Learning Methods (Linear regression, logistic regression, lasso, ridge regression, Multi-Class Classification, Tree and Ensemble Models), Unsupervised Learning Methods (Clustering: K-means, K-Medians, K-Medoids, Hierarchical Clustering; Dimensionality Reduction: PCA, PCR) | Language: Python, SQL (PostgreSQL, MySQL), NoSQL (MongoDB), XML | Data Visualization &amp; Dashboard: Google Data Studio, GGplot for python, Plotly, Cufflinks, Matplotlib, seaborn | . INDUSTRY EXPERIENCE: . Data Engineering Indutry Experience: Driving SIA’s big data, DataOps and MLOps transformation, implementing operational ML and Data pipeline workflows. Enhancing in-house self-service data ingestion portal, enabling non-technical users to ingest data from multiple source systems to Datalake &amp; Data marts. Impactfully shortening data pipeline development from 4 months to 2 weeks. Building data pipelines on Airflow for advanced analytics and ML use cases. Refractor and maintain Data Ops infrastructure, promoting best coding practices and open source tools for cost effective infra. Leading an interesting POC for ETL tool migration (IBM Ab Initio), design architecture suitable for both on-premise &amp; cloud (exploring Airflow, Kafka, Confluent). Owned end-to-end development of a serverless solution to crawl online customer feedbacks from multiple websites and ingest into data lake, contributing 30% more data to existing Customer Insights Portal (CIP) (AWS CloudWatch, Lambda, DynamoDB, S3, Selenium) | Data Science industry experience: Excitedly worked on cutting edge Applied ML and AI technologies in the Real-estate market for Houzen Holdings based out of London, UK. Launched AI Valuation price prediction model for UK based properties by EDA on enormous amount of live property data. Experienced at AWS Backend Engineering services and APIs, GCP(Vision Tables, BigTable, Storage and integration through APIs), Google Data Studio for dashboard and visualization. | Backend Software Developer Industry Experience: Experienced Software Developer in Java and Python. Worked with Microservices, RESTful APIs, RDBMS, An adaptive team player exposed to end-to-end software development lifecycle. | . EDUCATION: . Master of Science in Business Analytics(MSBA) at NUS, Singapore. Learning all about solving business problems with interpretable and implementable Data Science Techniques. | Bachelor of Engineering(B.E) from Netaji Subhas Institute of Technology(NSIT), New Delhi India | .",
          "url": "https://contactmansi.github.io/workoutdata/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://contactmansi.github.io/workoutdata/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}